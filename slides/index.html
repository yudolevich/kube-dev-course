
<!DOCTYPE html>

<html lang="ru">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <title></title>
    <link rel="stylesheet" type="text/css" href="_static/revealjs4/dist/reveal.css" />
    <link rel="stylesheet" href="_static/revealjs4/dist/theme/league.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/revealjs4/plugin/highlight/zenburn.css" />
    <script src="https://unpkg.com/mermaid@9.4.0/dist/mermaid.min.js"></script>
    <script>mermaid.initialize({startOnLoad:true});</script>
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

  </head><body>
    <div class="reveal">
        <div class="slides" role="main">
            <section >
<h1></h1>
<a class="reference internal image-reference" href="_images/logo.svg"><img alt="_images/logo.svg" src="_images/logo.svg" width="200px" /></a>
</section>
<section>
<section >
<h2>Основные концепции</h2>
<a class="reference internal image-reference" href="_images/control-plane.svg"><img alt="_images/control-plane.svg" src="_images/control-plane.svg" width="200px" /></a>
</section>
<section >
<h3>Эволюция инфраструктуры</h3>
<p><img alt="" src="_images/container_evolution3.svg" /></p>
</section>
<section >
<h3></h3>
<p>Физические сервера</p>
<p><img alt="" src="_images/container_evolution1.svg" /></p>
</section>
<section >
<h3></h3>
<p>Физические сервера</p>
<p>Минусы</p>
<ul class="simple">
<li class="fragment"><p>борьба приложений за ресурсы</p></li>
<li class="fragment"><p>проблема вертикального масштабирования</p></li>
<li class="fragment"><p>неэффективное использование ресурсов</p></li>
</ul>
</section>
<section >
<h3></h3>
<p>Виртуализация</p>
<p><img alt="" src="_images/container_evolution2.svg" /></p>
</section>
<section >
<h3></h3>
<p>Виртуализация</p>
<ul class="simple">
<li class="fragment"><p>ресурсы ограничены параметрами виртуальной машины</p></li>
<li class="fragment"><p>простота вертикального масштабирования</p></li>
<li class="fragment"><p>возможность более плотного размещения</p></li>
</ul>
</section>
<section >
<h3></h3>
<p>Контейнеры</p>
<p><img alt="" src="_images/container_evolution3.svg" /></p>
<p class="fragment">Зачем?</p>
</section>
<section >
<h3></h3>
<p>Отличие контейнеров от ВМ</p>
<ul class="simple">
<li class="fragment"><p>изоляция на уровне ОС</p></li>
<li class="fragment"><p>запускается только нужное приложение</p></li>
<li class="fragment"><p>минимальные накладные расходы</p></li>
</ul>
</section>
<section >
<h3></h3>
<p>DevOps практики</p>
<ul class="simple">
<li class="fragment"><p>гибкость создания и развертывания с docker image</p></li>
<li class="fragment"><p>одинаково работает при разработке, тестировании и на проде</p></li>
<li class="fragment"><p>удобство использования в CI/CD</p></li>
<li class="fragment"><p>хорошо подходит для микросервисной архитектуры</p></li>
</ul>
</section>
<section >
<h3>Эволюция архитектуры приложений</h3>
<p><img alt="" src="_images/monolithvsmicro.drawio.svg" /></p>
</section>
<section >
<h3></h3>
<p>Монолитная архитектура</p>
<p><img alt="" src="_images/monolith.drawio.svg" /></p>
</section>
<section >
<h3></h3>
<p>Монолитная архитектура</p>
<ul class="simple">
<li class="fragment"><p>изменения одного компонента требуют редеплой всего приложения</p></li>
<li class="fragment"><p>требуются мощные сервера, проблема масштабирования</p></li>
<li class="fragment"><p>нельзя масштабировать только нужные компоненты</p></li>
<li class="fragment"><p>отказ одного компонента ведет к полной неработоспособности</p></li>
<li class="fragment"><p>сложная структура проекта, тяжело заменять компоненты</p></li>
</ul>
</section>
<section >
<h3></h3>
<p>Микросервисная архитектура</p>
<p><img alt="" src="_images/microservices.drawio.svg" /></p>
</section>
<section >
<h3></h3>
<p>Микросервисная архитектура</p>
<ul class="simple">
<li class="fragment"><p>можно обновлять независимо</p></li>
<li class="fragment"><p>меньше требования к ресурсам, легко масштабировать горизонтально</p></li>
<li class="fragment"><p>можно масштабировать только необходимые компоненты</p></li>
<li class="fragment"><p>при отказе затрагивает только связанные компоненты</p></li>
<li class="fragment"><p>разработка на разных языках и технологиях</p></li>
</ul>
</section>
<section >
<h3>Kubernetes</h3>
<a class="reference internal image-reference" href="_images/logo.svg"><img alt="_images/logo.svg" src="_images/logo.svg" width="100px" /></a>
<ul class="simple">
<li class="fragment"><p>размещение и жизненный цикл контейнеров</p></li>
<li class="fragment"><p>масштабирование и распределение нагрузки</p></li>
<li class="fragment"><p>конфигурация через декларативное описание</p></li>
</ul>
</section>
<section >
<h3></h3>
<p>Основные компоненты</p>
<ul class="simple">
<li class="fragment"><p>control-plane <img alt="" src="_images/control-plane.svg" /></p></li>
<li class="fragment"><p>node components <img alt="" src="_images/node.svg" /></p></li>
</ul>
</section>
<section >
<h3>Control Plane</h3>
<p><img alt="" src="_images/control-plane.svg" /></p>
<ul class="simple">
<li class="fragment"><p>обработка операций взаимодействия с кластером</p></li>
<li class="fragment"><p>управления размещением нагрузки по нодам</p></li>
<li class="fragment"><p>отслеживание ресурсов и событий в кластере и их обработка</p></li>
</ul>
</section>
<section >
<h3>Control Plane</h3>
<ul class="simple">
<li class="fragment"><p>kube-apiserver <img alt="" src="_images/api.svg" /></p></li>
<li class="fragment"><p>etcd <img alt="" src="_images/etcd.svg" /></p></li>
</ul>
</section>
<section >
<h3>Control Plane</h3>
<ul class="simple">
<li class="fragment"><p>kube-scheduler <img alt="" src="_images/sched.svg" /></p></li>
<li class="fragment"><p>kube-controller-manager <img alt="" src="_images/c-m.svg" /></p></li>
<li class="fragment"><p>cloud-controller-manager <img alt="" src="_images/c-c-m.svg" /></p></li>
</ul>
</section>
<section >
<h3></h3>
<p>Отказоустойчивый кластер</p>
<p><img alt="" src="_images/ha-cluster.svg" /></p>
</section>
<section >
<h3>Node</h3>
<p><img alt="" src="_images/node.svg" /></p>
<ul class="simple">
<li class="fragment"><p>kubelet <img alt="" src="_images/kubelet.svg" /></p></li>
<li class="fragment"><p>kube-proxy <img alt="" src="_images/k-proxy.svg" /></p></li>
<li class="fragment"><p>container runtime <img alt="" src="_images/cri.svg" /></p></li>
</ul>
</section>
<section >
<h3>API Kubernetes</h3>
<p><img alt="" src="_images/api.svg" /></p>
</section>
<section >
<h3></h3>
<p>Объект в kubernetes</p>
<ul class="simple">
<li class="fragment"><p>Конфигурация и состояние нод кластера(Node)</p></li>
<li class="fragment"><p>Конфигурация и состояние развертывания приложения(Deployment)</p></li>
<li class="fragment"><p>Конфигурация данных для приложения(ConfigMap)</p></li>
</ul>
</section>
<section >
<h3></h3>
<p>Объект в kubernetes</p>
<pre data-id="id21"><code data-trim data-noescape class="yaml" data-line-numbers="1|2|3-7|8-14|15">apiVersion: v1
kind: Pod
metadata:
  creationTimestamp: null
  labels:
    run: nginx
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx
    resources: {}
  dnsPolicy: ClusterFirst
  restartPolicy: Always
status: {}</code></pre>
</section>
<section >
<h3></h3>
<p>REST</p>
<pre data-id="id22"><code data-trim data-noescape class="bash">$ kubectl get --raw /
{
  &quot;paths&quot;: [
    &quot;/.well-known/openid-configuration&quot;,
    &quot;/api&quot;,
    &quot;/api/v1&quot;,
    &quot;/apis&quot;,
    &quot;/apis/&quot;,
    &quot;/apis/apps&quot;,
    &quot;/apis/apps/v1&quot;,
    ...
</code></pre>
</section>
<section >
<h3></h3>
<p>Groups</p>
<ul class="simple">
<li class="fragment"><p>/api/v1 - core группа, соответствует<br />
apiVersion: v1</p></li>
<li class="fragment"><p>/apis/$GROUP/$VERSION - именованные группы, соответствует<br />
apiVersion: $GROUP/$VERSION</p></li>
</ul>
</section>
<section >
<h3></h3>
<p>Scope</p>
<pre data-id="id24"><code data-trim data-noescape class="bash" data-line-numbers="1-3|5-7"># для cluster-wide ресурсов
&quot;/apis/${GROUP}/${VERSION}/${RESOURCE}&quot;
(/apis/apiregistration.k8s.io/v1/apiservices)

# для namespaced ресурсов
&quot;/apis/${GROUP}/${VERSION}/namespaces/${NAMESPACE}/${RESOURCE}&quot;
(/apis/apps/v1/namespaces/default/deployments)</code></pre>
</section>
<section >
<h3></h3>
<p>Get Object</p>
<pre data-id="id25"><code data-trim data-noescape class="bash">&quot;/apis/$GROUP/$VERSION/namespaces/$NAMESPACE/$RESOURCE/$NAME&quot;</code></pre>
</section>
</section>
<section>
<section >
<h2>Pod</h2>
<a class="reference internal image-reference" href="_images/pod-unl.svg"><img alt="_images/pod-unl.svg" src="_images/pod-unl.svg" width="200px" /></a>
</section>
<section >
<h3></h3>
<p>Pod - это минимальная единица развертывания</p>
<ul class="simple">
<li class="fragment"><p>один или несколько контейнеров на одной ноде</p></li>
<li class="fragment"><p>общая сеть</p></li>
<li class="fragment"><p>общее хранилище</p></li>
<li class="fragment"><p>общий набор параметров</p></li>
</ul>
</section>
<section >
<h3></h3>
<pre data-id="id27"><code data-trim data-noescape class="yaml">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    ports:
    - containerPort: 80</code></pre>
<pre data-id="id27"><code data-trim data-noescape class="console">$ kubectl apply -f pod.yaml</code></pre>
</section>
<section >
<h3>Несколько контейнеров</h3>
<a class="reference internal image-reference" href="_images/pod-multicontainer.svg"><img alt="_images/pod-multicontainer.svg" class="align-center" src="_images/pod-multicontainer.svg" width="300px" /></a>
</section>
<section >
<h3></h3>
<pre data-id="id29"><code data-trim data-noescape class="yaml" data-line-numbers="7-8|9-11|12-13|14-16|17-20">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx:1.14.2
    volumeMounts:
    - mountPath: /opt/nginx/conf
      name: conf
  - name: reloader
    image: config-reloader:1.2.3
    volumeMounts:
    - mountPath: /opt/nginx/conf
      name: conf
  volumes:
  - name: conf
    configMap:
      name: conf</code></pre>
</section>
<section >
<h3>Жизненный цикл</h3>
<img alt="_images/lifecycle.svg" src="_images/lifecycle.svg" /></section>
<section >
<h3>Pod Phases</h3>
<ul class="simple">
<li class="fragment"><p><strong>Pending</strong> - под создан, но не назначен на ноду</p></li>
<li class="fragment"><p><strong>Running</strong> - под назначен и все контейнеры запущены</p></li>
<li class="fragment"><p><strong>Succeeded</strong> - все контейнеры успешно завершены</p></li>
<li class="fragment"><p><strong>Failed</strong> - все контейнеры завершены, но хотя бы один неуспешно</p></li>
<li class="fragment"><p><strong>Unknown</strong> - не удалось определить статус пода</p></li>
</ul>
</section>
<section >
<h3>Pod Conditions</h3>
<ul class="simple">
<li class="fragment"><p><strong>PodScheduled</strong> - под назначен на ноду</p></li>
<li class="fragment"><p><strong>ContainersReady</strong> - все контейнеры пода подготовлены</p></li>
<li class="fragment"><p><strong>Initialized</strong> - все инит контейнеры в поде выполнились успешно</p></li>
<li class="fragment"><p><strong>Ready</strong> - под готов принимать запросы</p></li>
</ul>
</section>
<section >
<h3>Container states</h3>
<ul class="simple">
<li class="fragment"><p><strong>Waiting</strong> - подготовительные операции для старта</p></li>
<li class="fragment"><p><strong>Running</strong> - контейнер запустился и работает</p></li>
<li class="fragment"><p><strong>Terminated</strong> - контейнер завершился</p></li>
</ul>
</section>
<section >
<h3>Container restart policy</h3>
<ul class="simple">
<li class="fragment"><p><strong>Always</strong> - при любом завершении контейнера</p></li>
<li class="fragment"><p><strong>OnFailure</strong> - при некорректном завершении</p></li>
<li class="fragment"><p><strong>Never</strong> - никогда не перезапускать</p></li>
</ul>
</section>
<section >
<h3>Container hooks</h3>
<ul class="simple">
<li class="fragment"><p><strong>PostStart</strong> - запускается сразу после создания контейнера</p></li>
<li class="fragment"><p><strong>PreStop</strong> - запускается непосредственно перед завершением контейнера</p></li>
</ul>
</section>
<section >
<h3>Container probes</h3>
<ul class="simple">
<li class="fragment"><p><strong>exec</strong> - выполняет команду внутри контейнера</p></li>
<li class="fragment"><p><strong>httpGet</strong> - выполняет HTTP GET запрос по IP пода</p></li>
<li class="fragment"><p><strong>tcpSocket</strong> - выполняет TCP проверку по IP и порту</p></li>
<li class="fragment"><p><strong>grpc</strong> - выполняет вызов удаленной процедуры по протоколу gRPC</p></li>
</ul>
</section>
<section >
<h3>Container probes</h3>
<ul class="simple">
<li class="fragment"><p><strong>livenessProbe</strong> - определяет, что контейнер работает</p></li>
<li class="fragment"><p><strong>readinessProbe</strong> - определяет, что контейнер готов принимать запросы</p></li>
<li class="fragment"><p><strong>startupProbe</strong> - определяет, что приложение в контейнере запустилось</p></li>
</ul>
</section>
<section >
<h3>Pod status</h3>
<pre data-id="pod-status"><code data-trim data-noescape class="yaml" data-line-numbers="2|3-6|7-10|11-14|15-18|19|20-27|28-30|31-37">status:
  conditions:
  - lastProbeTime: null
    lastTransitionTime: &quot;2023-03-03T14:38:28Z&quot;
    status: &quot;True&quot;
    type: Initialized
  - lastProbeTime: null
    lastTransitionTime: &quot;2023-03-03T14:39:31Z&quot;
    status: &quot;True&quot;
    type: Ready
  - lastProbeTime: null
    lastTransitionTime: &quot;2023-03-03T14:39:31Z&quot;
    status: &quot;True&quot;
    type: ContainersReady
  - lastProbeTime: null
    lastTransitionTime: &quot;2023-03-03T14:38:28Z&quot;
    status: &quot;True&quot;
    type: PodScheduled
  containerStatuses:
  - containerID: cri-o://83ae1cecc32ff20bc915438c265bae638b8741c371cd4b3006cbbfbf1aeb255c
    image: docker.io/library/nginx:latest
    imageID: docker.io/library/nginx&#64;sha256:3f13b4376446cf92b0cb9a5c46ba75d57c41f627c4edb8b635fa47386ea29e20
    lastState: {}
    name: nginx
    ready: true
    restartCount: 0
    started: true
    state:
      running:
        startedAt: &quot;2023-03-03T14:39:31Z&quot;
  hostIP: 172.18.0.3
  phase: Running
  podIP: 10.244.2.5
  podIPs:
  - ip: 10.244.2.5
  qosClass: Burstable
  startTime: &quot;2023-03-03T14:38:28Z&quot;</code></pre>
</section>
<section >
<h3>Pod status</h3>
<pre data-id="id32"><code data-trim data-noescape class="console">$ k get po
NAME    READY   STATUS    RESTARTS   AGE
nginx   1/1     Running   0          3d17h</code></pre>
</section>
<section >
<h3>Pod termination</h3>
<img alt="_images/terminate.svg" src="_images/terminate.svg" /></section>
<section >
<h3>Конфигурация</h3>
</section>
<section >
<h3></h3>
<pre data-id="id34"><code data-trim data-noescape class="console">$ # kubectl explain pod.&lt;field&gt;
$ kubectl explain pod.spec.containers.image
KIND:     Pod
VERSION:  v1

FIELD:    image &lt;string&gt;

DESCRIPTION:
     Docker image name. More info:
     https://kubernetes.io/docs/concepts/containers/images This field is
     optional to allow higher level config management to default or override
     container images in workload controllers like Deployments and StatefulSets.</code></pre>
</section>
<section >
<h3>Scheduling</h3>
<pre data-id="scheduling"><code data-trim data-noescape class="yaml" data-line-numbers="6">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  nodeName: kind-worker
  containers:
  - name: nginx
    image: nginx</code></pre>
</section>
<section >
<h3>Scheduling</h3>
<pre data-id="id35"><code data-trim data-noescape class="yaml" data-line-numbers="6-7">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  nodeSelector:
    kubernetes.io/hostname: kind-worker
  containers:
  - name: nginx
    image: nginx</code></pre>
</section>
<section >
<h3>Scheduling</h3>
<pre data-id="id36"><code data-trim data-noescape class="yaml" data-line-numbers="6-14">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: kubernetes.io/hostname
            operator: In
            values:
            - kind-worker
  containers:
  - name: nginx
    image: nginx</code></pre>
</section>
<section >
<h3>Pod Lifecycle</h3>
<pre data-id="pod-lifecycle"><code data-trim data-noescape class="yaml" data-line-numbers="6-8">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  restartPolicy: Never
  terminationGracePeriodSeconds: 5
  activeDeadlineSeconds: 10
  containers:
  - image: nginx
    name: nginx</code></pre>
</section>
<section >
<h3>Pod Volumes</h3>
<pre data-id="pod-volumes"><code data-trim data-noescape class="yaml" data-line-numbers="12-14">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx
    volumeMounts:
    - name: data
      mountPath: /data/
  volumes:
  - name: data
    emptyDir: {}</code></pre>
</section>
<section >
<h3>Name Resolution</h3>
<ul class="simple">
<li class="fragment"><p><em>hostname</em> - позволяет задать хостнейм для пода.</p></li>
<li class="fragment"><p><em>subdomain</em> - позволяет задать fqdn хостнейм для пода в виде<br />
<em>hostname.subdomain.namespace.svc.cluster.local</em>.</p></li>
</ul>
</section>
<section >
<h3>Name Resolution</h3>
<pre data-id="id37"><code data-trim data-noescape class="yaml" data-line-numbers="6-14">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  hostAliases:
  - ip: &quot;127.0.0.1&quot;
    hostnames:
    - &quot;foo.local&quot;
    - &quot;bar.local&quot;
  - ip: &quot;10.1.2.3&quot;
    hostnames:
    - &quot;foo.remote&quot;
    - &quot;bar.remote&quot;
  containers:
  - image: nginx
    name: nginx</code></pre>
</section>
<section >
<h3>Name Resolution</h3>
<pre data-id="id38"><code data-trim data-noescape class="yaml" data-line-numbers="6|7-10">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  dnsPolicy: &quot;None&quot;
  dnsConfig:
    nameservers:
    - 8.8.8.8
    - 8.8.4.4
  containers:
  - image: nginx
    name: nginx</code></pre>
</section>
<section >
<h3>Hosts namespaces</h3>
<pre data-id="hosts-namespaces"><code data-trim data-noescape class="yaml" data-line-numbers="6-7">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  hostNetwork: true
  shareProcessNamespace: true
  containers:
  - image: nginx
    name: nginx</code></pre>
</section>
<section >
<h3>Service account</h3>
<pre data-id="service-account"><code data-trim data-noescape class="yaml" data-line-numbers="6-7">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  serviceAccountName: default
  automountServiceAccountToken: false
  containers:
  - image: nginx
    name: nginx</code></pre>
</section>
<section >
<h3>Pod Security Context</h3>
<pre data-id="pod-security-context"><code data-trim data-noescape class="yaml" data-line-numbers="6-10">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  securityContext:
    runAsNonRoot: true
    runAsUser: 1000
    runAsGroup: 3000
    fsGroup: 2000
  containers:
  - image: nginx
    name: nginx</code></pre>
</section>
<section >
<h3>Containers</h3>
<pre data-id="containers"><code data-trim data-noescape class="yaml" data-line-numbers="6-7|8-11|12-14">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  imagePullSecrets:
  - name: registry-cred
  initContainers:
  - name: init
    image: busybox:1.28
    command: ['sh', '-c', 'echo hello']
  containers:
  - image: nginx
    name: nginx</code></pre>
</section>
<section >
<h3>Конфигурация контейнера</h3>
</section>
<section >
<h3>Image</h3>
<pre data-id="image"><code data-trim data-noescape class="yaml" data-line-numbers="6|8">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  imagePullPolicy: Always
  containers:
  - image: nginx
    name: nginx</code></pre>
</section>
<section >
<h3>Entrypoint</h3>
<pre data-id="entrypoint"><code data-trim data-noescape class="yaml" data-line-numbers="9-11">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: echo
    image: busybox:1.28
    command: ['sh', '-c']
    args: ['echo $PWD']
    workingDir: /</code></pre>
</section>
<section >
<h3>Ports</h3>
<pre data-id="ports"><code data-trim data-noescape class="yaml" data-line-numbers="9-14">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx
    ports:
    - name: http
      containerPort: 80
      protocol: TCP
    - name: https
      containerPort: 443</code></pre>
</section>
<section >
<h3>Environment</h3>
<pre data-id="environment"><code data-trim data-noescape class="yaml" data-line-numbers="9-11|12-17|18-21">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx
    env:
    - name: KEY
      value: ENV_VALUE
    - name: KEY_FROM_SECRET
      valueFrom:
        secretKeyRef:
          name: config
          key: KEY
          optional: true
    envFrom:
    - configMapRef:
        name: config
        optional: true</code></pre>
</section>
<section >
<h3>Container Volumes</h3>
<pre data-id="container-volumes"><code data-trim data-noescape class="yaml" data-line-numbers="9-13">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - name: nginx
    image: nginx
    volumeMounts:
    - mountPath: /opt/nginx/conf
      readOnly: true
      subPath: conf
      name: conf
  volumes:
  - name: conf
    configMap:
      name: conf</code></pre>
</section>
<section >
<h3>Resources</h3>
<pre data-id="resources"><code data-trim data-noescape class="yaml" data-line-numbers="9-15|10-12|13-15">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx
    resources:
      requests:
        cpu: &quot;500m&quot;
        memory: &quot;100Mi&quot;
      limits:
        cpu: &quot;1&quot;
        memory: &quot;200Mi&quot;</code></pre>
</section>
<section >
<h3>Container Lifecycle</h3>
<pre data-id="container-lifecycle"><code data-trim data-noescape class="yaml" data-line-numbers="9-15">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx
    lifecycle:
      postStart:
        exec:
          command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo &gt; /var/index.html&quot;]
      preStop:
        exec:
          command: [&quot;/bin/sh&quot;,&quot;-c&quot;,&quot;nginx -s quit&quot;]</code></pre>
</section>
<section >
<h3>Container Lifecycle</h3>
<pre data-id="id40"><code data-trim data-noescape class="yaml" data-line-numbers="9-15|16-20|21-29">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx
    startupProbe:
      exec:
        command:
        - cat
        - /tmp/healthy
      initialDelaySeconds: 5
      periodSeconds: 5
    readinessProbe:
      tcpSocket:
        port: 8080
      initialDelaySeconds: 5
      periodSeconds: 10
    livenessProbe:
      httpGet:
        path: /healthz
        port: 8080
        httpHeaders:
        - name: Custom-Header
          value: Awesome
      initialDelaySeconds: 3
      periodSeconds: 3</code></pre>
</section>
<section >
<h3>Container Security Context</h3>
<pre data-id="container-security-context"><code data-trim data-noescape class="yaml" data-line-numbers="9-12">apiVersion: v1
kind: Pod
metadata:
  name: nginx
spec:
  containers:
  - image: nginx
    name: nginx
    securityContext:
      readOnlyRootFilesystem: true
      privileged: true</code></pre>
</section>
</section>
<section>
<section >
<h2>Workloads</h2>
<a class="reference internal image-reference" href="_images/workloads.svg"><img alt="_images/workloads.svg" src="_images/workloads.svg" width="200px" /></a>
</section>
<section >
<h3></h3>
<ul class="simple">
<li class="fragment"><p><strong>Deployment</strong> и <strong>ReplicaSet</strong></p></li>
<li class="fragment"><p><strong>StatefulSet</strong></p></li>
<li class="fragment"><p><strong>DaemonSet</strong></p></li>
<li class="fragment"><p><strong>Job</strong> и <strong>CronJob</strong></p></li>
</ul>
</section>
<section >
<h3>Deployment/ReplicaSet</h3>
<a class="reference internal image-reference" href="_images/deploy-rs-pod.svg"><img alt="_images/deploy-rs-pod.svg" src="_images/deploy-rs-pod.svg" width="500px" /></a>
</section>
<section >
<h3>ReplicaSet <img alt="" src="_images/rs.svg" /></h3>
<pre data-id="replicaset"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|8|9-11|12-19">apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: nginx-rs
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx</code></pre>
</section>
<section >
<h3>Deployment <img alt="" src="_images/deploy.svg" /></h3>
<pre data-id="deployment"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|8|9-10|11|12-14|15-22">apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
  revisionHistoryLimit: 5
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx</code></pre>
</section>
<section >
<h3>Selector</h3>
<pre data-id="selector"><code data-trim data-noescape class="yaml">  selector:
    matchLabels:
      app: nginx
      pod-template-hash: 76d6c9b8c
  template:
    metadata:
      labels:
        app: nginx
        pod-template-hash: 76d6c9b8c</code></pre>
</section>
<section >
<h3>Update</h3>
<ul class="simple">
<li class="fragment"><p><strong>Recreate</strong></p></li>
<li class="fragment"><p><strong>RollingUpdate</strong></p></li>
</ul>
</section>
<section >
<h3>Recreate</h3>
<pre data-id="recreate"><code data-trim data-noescape class="console" data-line-numbers="1-6|7-8|9-11|12-16|17-20|21-25|26-30">$ k get deploy
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     3            3           47h
$ k get rs
NAME                         DESIRED   CURRENT   READY   AGE
nginx-deployment-c5f8dc5d6   3         3         3       19s
$ k set env deploy/nginx-deployment ENV=&quot;$(date)&quot;
deployment.apps/nginx-deployment env updated
$ k get rs
NAME                         DESIRED   CURRENT   READY   AGE
nginx-deployment-c5f8dc5d6   0         0         0       36s
$ k get po
NAME                               READY   STATUS        RESTARTS   AGE
nginx-deployment-c5f8dc5d6-bqmcl   1/1     Terminating   0          38s
nginx-deployment-c5f8dc5d6-v7btw   1/1     Terminating   0          38s
nginx-deployment-c5f8dc5d6-wkx9w   1/1     Terminating   0          38s
$ k get rs
NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-6c86565b44   3         3         0       4s
nginx-deployment-c5f8dc5d6    0         0         0       45s
$ k get po
NAME                                READY   STATUS              RESTARTS   AGE
nginx-deployment-6c86565b44-4cx9r   0/1     ContainerCreating   0          8s
nginx-deployment-6c86565b44-dlvcz   0/1     ContainerCreating   0          8s
nginx-deployment-6c86565b44-dnnht   0/1     ContainerCreating   0          8s
$ k get po
NAME                                READY   STATUS    RESTARTS   AGE
nginx-deployment-6c86565b44-4cx9r   1/1     Running   0          16s
nginx-deployment-6c86565b44-dlvcz   1/1     Running   0          16s
nginx-deployment-6c86565b44-dnnht   1/1     Running   0          16s</code></pre>
</section>
<section >
<h3>RollingUpdate</h3>
<pre data-id="rollingupdate"><code data-trim data-noescape class="yaml" data-line-numbers="1-6|5|6">spec:
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%
      maxSurge: 25%</code></pre>
</section>
<section >
<h3>RollingUpdate</h3>
<pre data-id="id42"><code data-trim data-noescape class="console" data-line-numbers="1-26|3|5-7|8-10|11-13|14-16|17-19|20-22|23-26">$ k set env deploy/nginx-deployment ENV=&quot;$(date)&quot;
deployment.apps/nginx-deployment env updated
$ k get rs -w
NAME                          DESIRED   CURRENT   READY   AGE
nginx-deployment-9ccdcc857    3         3         3       28s
nginx-deployment-7c7dcd74b5   1         0         0       0s
nginx-deployment-7c7dcd74b5   1         0         0       0s
nginx-deployment-7c7dcd74b5   1         1         0       0s
nginx-deployment-7c7dcd74b5   1         1         1       5s
nginx-deployment-9ccdcc857    2         3         3       40s
nginx-deployment-9ccdcc857    2         3         3       41s
nginx-deployment-7c7dcd74b5   2         1         1       6s
nginx-deployment-9ccdcc857    2         2         2       41s
nginx-deployment-7c7dcd74b5   2         1         1       6s
nginx-deployment-7c7dcd74b5   2         2         1       7s
nginx-deployment-7c7dcd74b5   2         2         2       9s
nginx-deployment-9ccdcc857    1         2         2       44s
nginx-deployment-7c7dcd74b5   3         2         2       9s
nginx-deployment-9ccdcc857    1         2         2       44s
nginx-deployment-9ccdcc857    1         1         1       44s
nginx-deployment-7c7dcd74b5   3         2         2       9s
nginx-deployment-7c7dcd74b5   3         3         2       9s
nginx-deployment-7c7dcd74b5   3         3         3       15s
nginx-deployment-9ccdcc857    0         1         1       50s
nginx-deployment-9ccdcc857    0         1         1       50s
nginx-deployment-9ccdcc857    0         0         0       50s</code></pre>
</section>
<section >
<h3>Conditions</h3>
<pre data-id="conditions"><code data-trim data-noescape class="console" data-line-numbers="1|8|22-26|27-28|29-31">$ k describe deploy nginx-deployment
Name:                   nginx-deployment
Namespace:              default
CreationTimestamp:      Sat, 18 Mar 2023 23:42:34 +0300
Labels:                 app=nginx
Annotations:            deployment.kubernetes.io/revision: 3
Selector:               app=nginx
Replicas:               3 desired | 3 updated | 3 total | 3 available | 0 unavailable
StrategyType:           RollingUpdate
MinReadySeconds:        0
RollingUpdateStrategy:  25% max unavailable, 25% max surge
Pod Template:
  Labels:  app=nginx
  Containers:
   nginx:
    Image:        nginx
    Port:         &lt;none&gt;
    Host Port:    &lt;none&gt;
    Environment:  &lt;none&gt;
    Mounts:       &lt;none&gt;
  Volumes:        &lt;none&gt;
Conditions:
  Type           Status  Reason
  ----           ------  ------
  Available      True    MinimumReplicasAvailable
  Progressing    True    NewReplicaSetAvailable
OldReplicaSets:  &lt;none&gt;
NewReplicaSet:   nginx-deployment-76d6c9b8c (3/3 replicas created)
Events:
  Type    Reason             Age                    From                   Message
  ----    ------             ----                   ----                   -------
  Normal  ScalingReplicaSet  5m26s                  deployment-controller  Scaled up replica set nginx-deployment-76d6c9b8c to 3
  Normal  ScalingReplicaSet  4m44s                  deployment-controller  Scaled up replica set nginx-deployment-bc8fc6c46 to 1
  Normal  ScalingReplicaSet  4m35s                  deployment-controller  Scaled down replica set nginx-deployment-76d6c9b8c to 2 from 3
  Normal  ScalingReplicaSet  4m35s                  deployment-controller  Scaled up replica set nginx-deployment-bc8fc6c46 to 2 from 1
  Normal  ScalingReplicaSet  4m24s                  deployment-controller  Scaled down replica set nginx-deployment-76d6c9b8c to 1 from 2
  Normal  ScalingReplicaSet  4m24s                  deployment-controller  Scaled up replica set nginx-deployment-bc8fc6c46 to 3 from 2
  Normal  ScalingReplicaSet  4m17s                  deployment-controller  Scaled down replica set nginx-deployment-76d6c9b8c to 0 from 1
  Normal  ScalingReplicaSet  3m                     deployment-controller  Scaled up replica set nginx-deployment-76d6c9b8c to 1 from 0
  Normal  ScalingReplicaSet  2m57s                  deployment-controller  Scaled down replica set nginx-deployment-bc8fc6c46 to 2 from 3
  Normal  ScalingReplicaSet  2m39s (x4 over 2m57s)  deployment-controller  (combined from similar events): Scaled down replica set nginx-deployment-bc8fc6c46 to 0 from 1</code></pre>
</section>
<section >
<h3>Conditions</h3>
<pre data-id="id43"><code data-trim data-noescape class="default">Replicas: 3 desired | 2 updated | 4 total | 3 available | 1 unavailable
</code></pre>
<ul class="simple">
<li class="fragment"><p><strong>desired</strong> - ожидаемое количество реплик</p></li>
<li class="fragment"><p><strong>updated</strong> - количество реплик с новой версией</p></li>
<li class="fragment"><p><strong>total</strong> - общее количество существующих реплик(старой и новой версии)</p></li>
<li class="fragment"><p><strong>available</strong> - количество реплик в состоянии Ready</p></li>
<li class="fragment"><p><strong>unavailable</strong> - количество реплик в состоянии NotReady</p></li>
</ul>
</section>
<section >
<h3>Conditions</h3>
<pre data-id="id44"><code data-trim data-noescape class="default">OldReplicaSets:  nginx-deployment-76d6c9b8c (2/2 replicas created)
NewReplicaSet:   nginx-deployment-bc8fc6c46 (2/2 replicas created)
</code></pre>
</section>
<section >
<h3>Conditions</h3>
<ul class="simple">
<li class="fragment"><p><strong>Available</strong></p></li>
<li class="fragment"><p><strong>Progressing</strong></p></li>
<li class="fragment"><p><strong>ReplicaFailure</strong></p></li>
</ul>
</section>
<section >
<h3>StatefulSet <img alt="" src="_images/sts.svg" /></h3>
</section>
<section >
<h3>StatefulSet</h3>
<ul class="simple">
<li class="fragment"><p>Стабильные и уникальные сетевые идентификаторы</p></li>
<li class="fragment"><p>Стабильное постоянное хранилище</p></li>
<li class="fragment"><p>Упорядоченный процесс развертывания и увеличения реплик</p></li>
<li class="fragment"><p>Упорядоченный процесс обновления</p></li>
</ul>
</section>
<section >
<h3>StatefulSet</h3>
<pre data-id="id47"><code data-trim data-noescape class="yaml" data-line-numbers="2-14|16-19|21-23|24|25|26|27-28|29-42|43-51">---
apiVersion: v1
kind: Service
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  ports:
  - port: 80
    name: web
  clusterIP: None
  selector:
    app: nginx
---
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: web
spec:
  selector:
    matchLabels:
      app: nginx
  serviceName: &quot;nginx&quot;
  replicas: 3
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80
          name: web
        volumeMounts:
        - name: www
          mountPath: /usr/share/nginx/html
  volumeClaimTemplates:
  - metadata:
      name: www
    spec:
      accessModes: [ &quot;ReadWriteOnce&quot; ]
      storageClassName: &quot;standard&quot;
      resources:
        requests:
          storage: 100Mi</code></pre>
</section>
<section >
<h3>Pod Identity</h3>
<pre data-id="pod-identity"><code data-trim data-noescape class="console">$ k get pods
NAME    READY   STATUS    RESTARTS   AGE
web-0   1/1     Running   0          2m21s
web-1   1/1     Running   0          109s
web-2   1/1     Running   0          82s</code></pre>
</section>
<section >
<h3>DNS</h3>
<pre data-id="dns"><code data-trim data-noescape class="console" data-line-numbers="1-3|4-6|7-12">$ k exec web-0 -- /bin/sh -c 'echo $HOSTNAME &gt; /usr/share/nginx/html/index.html'
$ k exec web-1 -- /bin/sh -c 'echo $HOSTNAME &gt; /usr/share/nginx/html/index.html'
$ k exec web-2 -- /bin/sh -c 'echo $HOSTNAME &gt; /usr/share/nginx/html/index.html'
$ k exec -it web-0 -- /bin/bash
root&#64;web-0:/# curl web-0.nginx.default.svc.cluster.local
web-0
root&#64;web-0:/# curl web-0.nginx
web-0
root&#64;web-0:/# curl web-1.nginx
web-1
root&#64;web-0:/# curl web-2.nginx
web-2</code></pre>
</section>
<section >
<h3>Pod Management Policies</h3>
<ul class="simple">
<li class="fragment"><p>OrderedReady</p>
<ul>
<li><p>Увеличение реплик от 0 до N-1</p></li>
<li><p>Уменьшение реплик от N-1 до 0</p></li>
<li><p>Перед созданием предыдущие Running и Ready</p></li>
<li><p>Перед удалением предыдущие завершены и удалены</p></li>
</ul>
</li>
<li class="fragment"><p>Parallel</p></li>
</ul>
</section>
<section >
<h3>Update</h3>
<ul class="simple">
<li class="fragment"><p><strong>OnDelete</strong></p></li>
<li class="fragment"><p><strong>RollingUpdate</strong></p></li>
</ul>
</section>
<section >
<h3>DaemonSet <img alt="" src="_images/ds.svg" /></h3>
</section>
<section >
<h3>DaemonSet</h3>
<ul class="simple">
<li class="fragment"><p>Запуск контроллера, управляющего хранилищем на ноде</p></li>
<li class="fragment"><p>Запуск коллектора логов на ноде</p></li>
<li class="fragment"><p>Запуск агента мониторинга на ноде</p></li>
</ul>
</section>
<section >
<h3>DaemonSet</h3>
<pre data-id="id50"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|9-12|13-17|20-24|28-43">apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app.kubernetes.io/component: exporter
    app.kubernetes.io/name: node-exporter
  name: node-exporter
spec:
  selector:
    matchLabels:
      app.kubernetes.io/component: exporter
      app.kubernetes.io/name: node-exporter
  template:
    metadata:
      labels:
        app.kubernetes.io/component: exporter
        app.kubernetes.io/name: node-exporter
    spec:
      containers:
      - args:
        - --path.sysfs=/host/sys
        - --path.rootfs=/host/root
        name: node-exporter
        image: prom/node-exporter
        ports:
          - containerPort: 9100
            protocol: TCP
        volumeMounts:
        - mountPath: /host/sys
          mountPropagation: HostToContainer
          name: sys
          readOnly: true
        - mountPath: /host/root
          mountPropagation: HostToContainer
          name: root
          readOnly: true
      volumes:
      - hostPath:
          path: /sys
        name: sys
      - hostPath:
          path: /
        name: root</code></pre>
</section>
<section >
<h3>Pod Placement</h3>
<ul class="simple">
<li class="fragment"><p>spec.template.spec.nodeSelector</p></li>
<li class="fragment"><p>spec.template.spec.affinity.nodeAffinity</p></li>
<li class="fragment"><p>spec.template.spec.tolerations</p></li>
</ul>
</section>
<section >
<h3>Job <img alt="" src="_images/job.svg" /></h3>
</section>
<section >
<h3>Job</h3>
<pre data-id="id51"><code data-trim data-noescape class="yaml" data-line-numbers="1-4|6|7|8-14">apiVersion: batch/v1
kind: Job
metadata:
  name: hello
spec:
  backoffLimit: 3
  activeDeadlineSeconds: 30
  template:
    spec:
      containers:
      - name: hello
        image: busybox
        command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo hello&quot;]
      restartPolicy: Never</code></pre>
</section>
<section >
<h3>CronJob <img alt="" src="_images/cronjob.svg" /></h3>
</section>
<section >
<h3>CronJob</h3>
<pre data-id="id52"><code data-trim data-noescape class="yaml" data-line-numbers="1-4|6|7-17">apiVersion: batch/v1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: &quot;* * * * *&quot;
  jobTemplate:
    spec:
      backoffLimit: 3
      activeDeadlineSeconds: 30
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            command: [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo hello&quot;]
          restartPolicy: Never</code></pre>
</section>
<section >
<h3>Rollout <img alt="" src="_images/rollout.svg" /></h3>
<pre data-id="rollout"><code data-trim data-noescape class="console">$ kubectl rollout
</code></pre>
</section>
<section >
<h3>Status</h3>
<pre data-id="status"><code data-trim data-noescape class="console" data-line-numbers="3|4-12">$ k set env deploy/nginx-deployment ENV=&quot;$(date)&quot;
deployment.apps/nginx-deployment env updated
$ k rollout status deployment nginx-deployment
Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...
Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...
Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 out of 3 new replicas have been updated...
Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...
Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...
Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 2 out of 3 new replicas have been updated...
Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...
Waiting for deployment &quot;nginx-deployment&quot; rollout to finish: 1 old replicas are pending termination...
deployment &quot;nginx-deployment&quot; successfully rolled out</code></pre>
</section>
<section >
<h3>History</h3>
<pre data-id="history"><code data-trim data-noescape class="console" data-line-numbers="5|6-10|3-4">$ k set env deploy nginx-deployment ENV=&quot;$(date)&quot;
deployment.apps/nginx-deployment env updated
$ k annotate deploy/nginx-deployment kubernetes.io/change-cause=&quot;new date 1&quot;
deployment.apps/nginx-deployment annotated
$ k rollout history deploy/nginx-deployment
deployment.apps/nginx-deployment
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
2         &lt;none&gt;
3         new date 1</code></pre>
</section>
<section >
<h3>Pause/Resume</h3>
<pre data-id="pause-resume"><code data-trim data-noescape class="console" data-line-numbers="1-2|3-6|7-13|14-16|17-18|19-29">$ k rollout pause deploy/nginx-deployment
deployment.apps/nginx-deployment paused
$ k set env deploy nginx-deployment ENV=&quot;$(date)&quot;
deployment.apps/nginx-deployment env updated
$ k annotate deployment nginx-deployment kubernetes.io/change-cause=&quot;new date 3&quot;
deployment.apps/nginx-deployment annotated
$ k rollout history deploy/nginx-deployment
deployment.apps/nginx-deployment
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
2         &lt;none&gt;
3         new date 1
4         new date 2
$ k get deploy
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     0            3           3d22h
$ k rollout resume deploy/nginx-deployment
deployment.apps/nginx-deployment resumed
$ k get deploy
NAME               READY   UP-TO-DATE   AVAILABLE   AGE
nginx-deployment   3/3     3            3           3d22h
$ k rollout history deploy/nginx-deployment
deployment.apps/nginx-deployment
REVISION  CHANGE-CAUSE
1         &lt;none&gt;
2         &lt;none&gt;
3         new date 1
4         new date 2
5         new date 3</code></pre>
</section>
<section >
<h3>Rollback</h3>
<pre data-id="rollback"><code data-trim data-noescape class="console" data-line-numbers="1-6|7-8|9-14|15-16|17-22">$ k rollout history deploy/nginx-deployment
deployment.apps/nginx-deployment
REVISION  CHANGE-CAUSE
1         new date 1
2         new date 2
3         new date 3
$ k rollout undo deploy/nginx-deployment
deployment.apps/nginx-deployment rolled back
$ k rollout history deploy/nginx-deployment
deployment.apps/nginx-deployment
REVISION  CHANGE-CAUSE
1         new date 1
3         new date 3
4         new date 2
$ k rollout undo deploy/nginx-deployment --to-revision 1
deployment.apps/nginx-deployment rolled back
$ k rollout history deploy/nginx-deployment
deployment.apps/nginx-deployment
REVISION  CHANGE-CAUSE
3         new date 3
4         new date 2
5         new date 1</code></pre>
</section>
<section >
<h3>Restart</h3>
<pre data-id="restart"><code data-trim data-noescape class="console" data-line-numbers="1-2|3-9">$ k rollout restart deploy/nginx-deployment
deployment.apps/nginx-deployment restarted
$ k rollout history deploy/nginx-deployment
deployment.apps/nginx-deployment
REVISION  CHANGE-CAUSE
3         new date 3
4         new date 2
5         new date 1
6         new date 1</code></pre>
</section>
<section >
<h3>Scaling <img alt="" src="_images/scaling.svg" /></h3>
<pre data-id="scaling"><code data-trim data-noescape class="console">$ kubectl rollout
</code></pre>
</section>
<section >
<h3>Scaling</h3>
<pre data-id="id53"><code data-trim data-noescape class="console">$ curl -XPATCH -H &quot;Content-Type: application/merge-patch+json&quot; \
  &quot;https://${api}/apis/apps/v1/namespaces/default/deployments/nginx-deployment/scale&quot; \
  -d '{&quot;spec&quot;:{&quot;replicas&quot;:2}}'
</code></pre>
</section>
<section >
<h3>Scaling</h3>
<pre data-id="id54"><code data-trim data-noescape class="console" data-line-numbers="1-2|3-14|15-16|17-26|27-28">$ k scale --replicas=10 deploy/nginx-deployment
deployment.apps/nginx-deployment scaled
$ k get po
NAME                               READY   STATUS    RESTARTS   AGE
nginx-deployment-76d6c9b8c-56lvx   1/1     Running   0          31s
nginx-deployment-76d6c9b8c-6n5cn   1/1     Running   0          31s
nginx-deployment-76d6c9b8c-8fbrs   1/1     Running   0          31s
nginx-deployment-76d6c9b8c-bzj82   1/1     Running   0          32s
nginx-deployment-76d6c9b8c-cbpzt   1/1     Running   0          17m
nginx-deployment-76d6c9b8c-ljtql   1/1     Running   0          31s
nginx-deployment-76d6c9b8c-qqdkt   1/1     Running   0          31s
nginx-deployment-76d6c9b8c-tblnb   1/1     Running   0          17m
nginx-deployment-76d6c9b8c-wkn5b   1/1     Running   0          30s
nginx-deployment-76d6c9b8c-zvkkr   1/1     Running   0          31s
$ k scale --replicas=0 deploy/nginx-deployment
deployment.apps/nginx-deployment scaled
$ k get po
NAME                               READY   STATUS        RESTARTS   AGE
nginx-deployment-76d6c9b8c-56lvx   1/1     Terminating   0          43s
nginx-deployment-76d6c9b8c-8fbrs   0/1     Terminating   0          43s
nginx-deployment-76d6c9b8c-bzj82   1/1     Terminating   0          44s
nginx-deployment-76d6c9b8c-cbpzt   1/1     Terminating   0          17m
nginx-deployment-76d6c9b8c-ljtql   1/1     Terminating   0          43s
nginx-deployment-76d6c9b8c-qqdkt   0/1     Terminating   0          43s
nginx-deployment-76d6c9b8c-tblnb   1/1     Terminating   0          17m
nginx-deployment-76d6c9b8c-zvkkr   1/1     Terminating   0          43s
$ k get po
No resources found in default namespace.</code></pre>
</section>
<section >
<h3>Horizontal Pod Autoscaling</h3>
<a class="reference internal image-reference" href="_images/hpa-mermaid.svg"><img alt="_images/hpa-mermaid.svg" src="_images/hpa-mermaid.svg" width="500px" /></a>
</section>
<section >
<h3>Horizontal Pod Autoscaling</h3>
<pre data-id="id55"><code data-trim data-noescape class="console">$ kubectl autoscale deployment nginx-deployment --min=2 --max=5 --cpu-percent=80
horizontalpodautoscaler.autoscaling/nginx-deployment autoscaled</code></pre>
</section>
<section >
<h3>Horizontal Pod Autoscaling</h3>
<pre data-id="id56"><code data-trim data-noescape class="yaml" data-line-numbers="1-4|6|7|8-14|15-18">apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: nginx-deployment
spec:
  minReplicas: 2
  maxReplicas: 5
  metrics:
  - resource:
      name: cpu
      target:
        averageUtilization: 80
        type: Utilization
    type: Resource
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: nginx-deployment</code></pre>
</section>
<section >
<h3>Disruptions</h3>
</section>
<section >
<h3>Involuntary</h3>
<ul class="simple">
<li class="fragment"><p>Отказ железа на физической машине</p></li>
<li class="fragment"><p>Удаление ВМ по ошибке</p></li>
<li class="fragment"><p>Kernel panic</p></li>
<li class="fragment"><p>Отключение ноды от кластера из-за сетевых проблем</p></li>
</ul>
</section>
<section >
<h3>Voluntary</h3>
<ul class="simple">
<li class="fragment"><p>Обновление шаблона пода в Deployment</p></li>
<li class="fragment"><p>Выселение подов для обновления ноды</p></li>
<li class="fragment"><p>Автоскейлинг нод</p></li>
<li class="fragment"><p>Удаление пода с ноды для высвыбождения ресурсов</p></li>
</ul>
</section>
<section >
<h3>Dealing with disruptions</h3>
<ul class="simple">
<li class="fragment"><p>Правильно выставить ресурсы(requests/limits)</p></li>
<li class="fragment"><p>Использовать несколько реплик</p></li>
<li class="fragment"><p>Распределять реплики на разных нодах/зонах</p></li>
</ul>
</section>
<section >
<h3>Pod disruption budgets</h3>
<pre data-id="pod-disruption-budgets"><code data-trim data-noescape class="yaml" data-line-numbers="1-4|6|7-9">apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: nginx
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: nginx</code></pre>
</section>
<section >
<h3>Pod disruption budgets</h3>
<pre data-id="id57"><code data-trim data-noescape class="yaml" data-line-numbers="6">apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: nginx
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: nginx</code></pre>
</section>
</section>
<section>
<section >
<h2>Network/LoadBalance</h2>
<a class="reference internal image-reference" href="_images/svc.svg"><img alt="_images/svc.svg" src="_images/svc.svg" width="200px" /></a>
</section>
<section >
<h3>Networks</h3>
<ul class="simple">
<li class="fragment"><p>Node network</p></li>
<li class="fragment"><p>Pod network</p></li>
<li class="fragment"><p>Service network</p></li>
</ul>
</section>
<section >
<h3>Concepts</h3>
<ul class="simple">
<li class="fragment"><p>Service</p></li>
<li class="fragment"><p>Ingress</p></li>
<li class="fragment"><p>Network Policy</p></li>
<li class="fragment"><p>DNS</p></li>
</ul>
</section>
<section >
<h3>Service</h3>
<pre data-id="service"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|8-9|10|11|12|13|14|15">apiVersion: v1
kind: Service
metadata:
  labels:
    app: nginx
  name: nginx
spec:
  selector:
    app: nginx
  ports:
  - name: web
    port: 80
    protocol: TCP
    targetPort: 8080
  type: ClusterIP</code></pre>
</section>
<section >
<h3>Service types</h3>
<ul class="simple">
<li class="fragment"><p>ClusterIP</p></li>
<li class="fragment"><p>NodePort</p></li>
<li class="fragment"><p>LoadBalancer</p></li>
<li class="fragment"><p>ExternalName</p></li>
</ul>
</section>
<section >
<h3>Service expose</h3>
<pre data-id="service-expose"><code data-trim data-noescape class="console" data-line-numbers="1|2-15">$ k expose deploy nginx-deployment --port 80 --dry-run=client -o yaml
apiVersion: v1
kind: Service
metadata:
  creationTimestamp: null
  labels:
    app: nginx
  name: nginx-deployment
spec:
  ports:
  - port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: nginx</code></pre>
</section>
<section >
<h3>Endpoints</h3>
<pre data-id="endpoints"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|8-9|10|11|12-16|31-34">apiVersion: v1
kind: Endpoints
metadata:
  labels:
    app: nginx
  name: nginx
  namespace: default
subsets:
- addresses:
  - ip: 10.244.1.5
    nodeName: kind-worker2
    targetRef:
      kind: Pod
      name: nginx-deployment-76d6c9b8c-n6c4f
      namespace: default
      uid: 7ec844ca-36d9-4082-a7ea-e0cd8e95d390
  - ip: 10.244.2.25
    nodeName: kind-worker
    targetRef:
      kind: Pod
      name: nginx-deployment-76d6c9b8c-9h2fn
      namespace: default
      uid: a93b7fd4-43b1-4c85-897b-3d150a8ec3dd
  - ip: 10.244.2.26
    nodeName: kind-worker
    targetRef:
      kind: Pod
      name: nginx-deployment-76d6c9b8c-r9vll
      namespace: default
      uid: d31680a6-1aad-439c-84a2-aee8c5d1930e
  ports:
  - name: web
    port: 8080
    protocol: TCP</code></pre>
</section>
<section >
<h3>Ingress</h3>
<p><img alt="" src="_images/ingress-diag.svg" /></p>
</section>
<section >
<h3>Ingress</h3>
<p><img alt="" src="_images/ingress-diag2.svg" /></p>
</section>
<section >
<h3>Ingress</h3>
<p><img alt="" src="_images/ingress-diag3.svg" /></p>
</section>
<section >
<h3>Ingress Spec</h3>
<ul class="simple">
<li class="fragment"><p>rules</p></li>
<li class="fragment"><p>ingressClassName</p></li>
<li class="fragment"><p>tls</p></li>
<li class="fragment"><p>defaultBackend</p></li>
</ul>
</section>
<section >
<h3>Ingress</h3>
<pre data-id="id60"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|6|7|8-11|12-16|17-26">apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: example-ingress
spec:
  rules:
  - host: app.example.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: frontend
            port:
              name: http
  - host: api.example.com
    http:
      paths:
      - path: /api
        pathType: Prefix
        backend:
          service:
            name: backend
            port:
              name: http</code></pre>
</section>
<section >
<h3>Ingress create</h3>
<pre data-id="ingress-create"><code data-trim data-noescape class="console" data-line-numbers="1|2-18">$ k create ingress test --rule 'example.com/*=svc:8080' --dry-run=client -o yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  creationTimestamp: null
  name: test
spec:
  rules:
  - host: example.com
    http:
      paths:
      - backend:
          service:
            name: svc
            port:
              number: 8080
        path: /
        pathType: Prefix</code></pre>
</section>
<section >
<h3>Network Policies</h3>
<p class="fragment">Entities</p>
<ul class="simple">
<li class="fragment"><p>Pods</p></li>
<li class="fragment"><p>Namespaces</p></li>
<li class="fragment"><p>IP Blocks</p></li>
</ul>
</section>
<section >
<h3>Network Policies</h3>
<pre data-id="id61"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|7-9|10-12|13|15-18|19-21|22-24|25-27|28|29-34">apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: netpol
  namespace: default
spec:
  podSelector:
    matchLabels:
      role: db
  policyTypes:
    - Ingress
    - Egress
  ingress:
    - from:
        - ipBlock:
            cidr: 172.17.0.0/16
            except:
              - 172.17.1.0/24
        - namespaceSelector:
            matchLabels:
              project: myproject
        - podSelector:
            matchLabels:
              role: frontend
      ports:
        - protocol: TCP
          port: 6379
  egress:
    - to:
        - ipBlock:
            cidr: 10.0.0.0/24
      ports:
        - protocol: TCP
          port: 5978</code></pre>
</section>
<section >
<h3>DNS</h3>
<p class="fragment">Service:</p>
<ul class="simple">
<li class="fragment"><p>svc-name.namespace.svc.cluster.local</p></li>
</ul>
<p class="fragment">Pod:</p>
<ul class="simple">
<li class="fragment"><p>pod-ip.namespace.pod.cluster.local</p></li>
<li class="fragment"><p>pod-ip.svcname.namespace.svc.cluster.local</p></li>
</ul>
</section>
<section >
<h3>Use Cases</h3>
</section>
<section >
<h3>Rolling Update</h3>
<a class="reference internal image-reference" href="_images/rollingupdate1.svg"><img alt="_images/rollingupdate1.svg" src="_images/rollingupdate1.svg" width="500px" /></a>
</section>
<section >
<h3>Rolling Update</h3>
<a class="reference internal image-reference" href="_images/rollingupdate2.svg"><img alt="_images/rollingupdate2.svg" src="_images/rollingupdate2.svg" width="500px" /></a>
</section>
<section >
<h3>Rolling Update</h3>
<a class="reference internal image-reference" href="_images/rollingupdate3.svg"><img alt="_images/rollingupdate3.svg" src="_images/rollingupdate3.svg" width="500px" /></a>
</section>
<section >
<h3>Rolling Update</h3>
<a class="reference internal image-reference" href="_images/rollingupdate4.svg"><img alt="_images/rollingupdate4.svg" src="_images/rollingupdate4.svg" width="500px" /></a>
</section>
<section >
<h3>Blue/Green Deploy</h3>
<a class="reference internal image-reference" href="_images/bluegreen1.svg"><img alt="_images/bluegreen1.svg" src="_images/bluegreen1.svg" width="500px" /></a>
</section>
<section >
<h3>Blue/Green Deploy</h3>
<a class="reference internal image-reference" href="_images/bluegreen2.svg"><img alt="_images/bluegreen2.svg" src="_images/bluegreen2.svg" width="500px" /></a>
</section>
<section >
<h3>Blue/Green Deploy</h3>
<a class="reference internal image-reference" href="_images/bluegreen3.svg"><img alt="_images/bluegreen3.svg" src="_images/bluegreen3.svg" width="500px" /></a>
</section>
<section >
<h3>Blue/Green Deploy</h3>
<a class="reference internal image-reference" href="_images/bluegreen4.svg"><img alt="_images/bluegreen4.svg" src="_images/bluegreen4.svg" width="500px" /></a>
</section>
<section >
<h3>Blue/Green Deploy</h3>
<pre data-id="id69"><code data-trim data-noescape class="console" data-line-numbers="1-20|13-20|23-27|30-44|42-43|47-52|54-73|66-73|76-83|84-89|91-92|93-98|100-101">$ k apply -f - &lt;&lt; EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-v1
  labels:
    app: nginx-v1
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-v1
  template:
    metadata:
      labels:
        app: nginx-v1
    spec:
      containers:
      - name: nginx
        image: nginx
EOF
deployment.apps/nginx-v1 created
$ k get po
NAME                        READY   STATUS    RESTARTS   AGE
nginx-v1-6c5f795c6f-794rl   1/1     Running   0          11s
nginx-v1-6c5f795c6f-9g596   1/1     Running   0          11s
nginx-v1-6c5f795c6f-zbrnp   1/1     Running   0          11s

$ k apply -f - &lt;&lt; EOF
apiVersion: v1
kind: Service
metadata:
  labels:
    app: nginx
  name: nginx
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: nginx-v1
  type: ClusterIP
EOF
service/nginx created
$ k get svc nginx
NAME    TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
nginx   ClusterIP   10.96.148.240   &lt;none&gt;        80/TCP    6s
$ k get ep nginx
NAME    ENDPOINTS                                      AGE
nginx   10.244.1.53:80,10.244.2.18:80,10.244.2.19:80   10s

$ k apply -f - &lt;&lt; EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-v2
  labels:
    app: nginx-v2
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx-v2
  template:
    metadata:
      labels:
        app: nginx-v2
    spec:
      containers:
      - name: nginx
        image: nginx:1.23
EOF
deployment.apps/nginx-v2 created
$ k get po
NAME                        READY   STATUS    RESTARTS   AGE
nginx-v1-6c5f795c6f-794rl   1/1     Running   0          2m42s
nginx-v1-6c5f795c6f-9g596   1/1     Running   0          2m42s
nginx-v1-6c5f795c6f-zbrnp   1/1     Running   0          2m42s
nginx-v2-7dcd48768d-5rmrn   1/1     Running   0          29s
nginx-v2-7dcd48768d-c5zps   1/1     Running   0          29s
nginx-v2-7dcd48768d-gphlv   1/1     Running   0          29s
$ k get svc,ep nginx
NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/nginx   ClusterIP   10.96.148.240   &lt;none&gt;        80/TCP    2m8s

NAME              ENDPOINTS                                      AGE
endpoints/nginx   10.244.1.53:80,10.244.2.18:80,10.244.2.19:80   2m7s

$ k patch -p '{&quot;spec&quot;:{&quot;selector&quot;:{&quot;app&quot;: &quot;nginx-v2&quot;}}}' svc nginx
service/nginx patched
$ k get svc,ep nginx
NAME            TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)   AGE
service/nginx   ClusterIP   10.96.148.240   &lt;none&gt;        80/TCP    3m45s

NAME              ENDPOINTS                                      AGE
endpoints/nginx   10.244.1.54:80,10.244.1.55:80,10.244.2.20:80   3m44s

$ k delete deployments.apps nginx-v1
deployment.apps &quot;nginx-v1&quot; deleted</code></pre>
</section>
<section >
<h3>Canary Release</h3>
<a class="reference internal image-reference" href="_images/canary1.svg"><img alt="_images/canary1.svg" src="_images/canary1.svg" width="500px" /></a>
</section>
<section >
<h3>Canary Release</h3>
<a class="reference internal image-reference" href="_images/canary2.svg"><img alt="_images/canary2.svg" src="_images/canary2.svg" width="500px" /></a>
</section>
<section >
<h3>Canary Release</h3>
<a class="reference internal image-reference" href="_images/canary3.svg"><img alt="_images/canary3.svg" src="_images/canary3.svg" width="500px" /></a>
</section>
<section >
<h3>Canary Release</h3>
<pre data-id="id72"><code data-trim data-noescape class="console" data-line-numbers="1-22|14-22|25-41|38-39|43-53|55-76|68-76|79-81|83-91|93-98|100-106">$ k apply -f - &lt;&lt; EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
      release: production
  template:
    metadata:
      labels:
        app: nginx
        release: production
    spec:
      containers:
      - name: nginx
        image: nginx
EOF

$ k apply -f - &lt;&lt; EOF
apiVersion: v1
kind: Service
metadata:
  labels:
    app: nginx
  name: nginx
spec:
  ports:
  - name: http
    port: 80
    protocol: TCP
    targetPort: 80
  selector:
    app: nginx
  type: ClusterIP
EOF

$ k get po
NAME                  READY STATUS  RESTARTS AGE
nginx-594f548d5-lq7zs 1/1   Running 0        2m14s
nginx-594f548d5-rxscl 1/1   Running 0        2m14s
nginx-594f548d5-x6ntm 1/1   Running 0        2m14s
$ k get svc nginx
NAME    TYPE        CLUSTER-IP     EXTERNAL-IP   PORT(S)   AGE
nginx   ClusterIP   10.96.19.136   &lt;none&gt;        80/TCP    40s
$ k get ep nginx
NAME    ENDPOINTS                                      AGE
nginx   10.244.1.50:80,10.244.1.51:80,10.244.2.14:80   75s

$ k apply -f - &lt;&lt; EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-canary
  labels:
    app: nginx
spec:
  replicas: 1
  selector:
    matchLabels:
      app: nginx
      release: canary
  template:
    metadata:
      labels:
        app: nginx
        release: canary
    spec:
      containers:
      - name: nginx
        image: nginx:1.23
EOF

$ k get ep nginx
NAME    ENDPOINTS                                                  AGE
nginx   10.244.1.50:80,10.244.1.51:80,10.244.2.14:80 + 1 more...   3m26s

$ k set image deploy/nginx nginx=nginx:1.23
deployment.apps/nginx image updated
$ k get po
NAME                          READY   STATUS        RESTARTS   AGE
nginx-5697c7f6ff-2h6tn        1/1     Running       0          10s
nginx-5697c7f6ff-lw2sf        1/1     Running       0          18s
nginx-5697c7f6ff-sdp95        1/1     Running       0          25s
nginx-594f548d5-x6ntm         1/1     Terminating   0          8m22s
nginx-canary-cd89655d-p8gv8   1/1     Running       0          3m27s

$ k get po
NAME                          READY   STATUS    RESTARTS   AGE
nginx-5697c7f6ff-2h6tn        1/1     Running   0          17s
nginx-5697c7f6ff-lw2sf        1/1     Running   0          25s
nginx-5697c7f6ff-sdp95        1/1     Running   0          32s
nginx-canary-cd89655d-p8gv8   1/1     Running   0          3m34s

$ k delete deploy nginx-canary
deployment.apps &quot;nginx-canary&quot; deleted
$ k get po
NAME                     READY   STATUS    RESTARTS   AGE
nginx-5697c7f6ff-2h6tn   1/1     Running   0          79s
nginx-5697c7f6ff-lw2sf   1/1     Running   0          87s
nginx-5697c7f6ff-sdp95   1/1     Running   0          94s</code></pre>
</section>
</section>
<section>
<section >
<h2>Storage</h2>
<a class="reference internal image-reference" href="_images/pv.svg"><img alt="_images/pv.svg" src="_images/pv.svg" width="200px" /></a>
</section>
<section >
<h3>Storage</h3>
<ul class="simple">
<li class="fragment"><p>Volumes</p></li>
<li class="fragment"><p>StorageClass</p></li>
<li class="fragment"><p>PersistentVolumeClaim</p></li>
<li class="fragment"><p>PersistentVolume</p></li>
<li class="fragment"><p>VolumeSnapshotClass</p></li>
<li class="fragment"><p>VolumeSnapshot</p></li>
</ul>
</section>
<section >
<h3>Volumes</h3>
<a class="reference internal image-reference" href="_images/vol.svg"><img alt="_images/vol.svg" src="_images/vol.svg" width="500px" /></a>
</section>
<section >
<h3>Volumes</h3>
<pre data-id="id74"><code data-trim data-noescape class="yaml" data-line-numbers="14|16|17-19|15|9-13">apiVersion: v1
kind: Pod
metadata:
  name: test-pd
spec:
  containers:
  - image: registry.k8s.io/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /my-nfs-data
      name: test-volume
      readOnly: true
      subPath: /my-nfs-data/path
  volumes:
  - name: test-volume
    nfs:
      server: my-nfs-server.example.com
      path: /my-nfs-volume
      readOnly: true</code></pre>
</section>
<section >
<h3>Ephemeral Volumes</h3>
</section>
<section >
<h3>EmptyDir</h3>
<pre data-id="emptydir"><code data-trim data-noescape class="yaml" data-line-numbers="14|15|16">apiVersion: v1
kind: Pod
metadata:
  name: test-pd
spec:
  containers:
  - image: registry.k8s.io/test-webserver
    name: test-container
    volumeMounts:
    - mountPath: /cache
      name: cache-volume
  volumes:
  - name: cache-volume
    emptyDir:
      medium: Memory
      sizeLimit: 500Mi</code></pre>
</section>
<section >
<h3>ConfigMap</h3>
<a class="reference internal image-reference" href="_images/cm.svg"><img alt="_images/cm.svg" src="_images/cm.svg" width="500px" /></a>
</section>
<section >
<h3>ConfigMap</h3>
<pre data-id="id75"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|5-7">apiVersion: v1
kind: ConfigMap
metadata:
  name: log-config
data:
  log_level: debug
  path: /data</code></pre>
</section>
<section >
<h3>ConfigMap</h3>
<pre data-id="id76"><code data-trim data-noescape class="yaml" data-line-numbers="14|15|16|17-18|19">apiVersion: v1
kind: Pod
metadata:
  name: configmap-pod
spec:
  containers:
    - name: test
      image: busybox:1.28
      volumeMounts:
        - name: config-vol
          mountPath: /etc/config
  volumes:
    - name: config-vol
      configMap:
        name: log-config
        items:
          - key: log_level
            path: log_level
        optional: false</code></pre>
</section>
<section >
<h3>Secret</h3>
<a class="reference internal image-reference" href="_images/secret.svg"><img alt="_images/secret.svg" src="_images/secret.svg" width="500px" /></a>
</section>
<section >
<h3>Secret</h3>
<pre data-id="id77"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|5-7">apiVersion: v1
kind: Secret
metadata:
  name: mysecret
data:
  key: dmFsdWU=
type: Opaque</code></pre>
</section>
<section >
<h3>Secret</h3>
<pre data-id="id78"><code data-trim data-noescape class="yaml" data-line-numbers="14|15|16|17">apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
  - name: mypod
    image: redis
    volumeMounts:
    - name: foo
      mountPath: &quot;/etc/foo&quot;
      readOnly: true
  volumes:
  - name: foo
    secret:
      secretName: mysecret
      optional: true</code></pre>
</section>
<section >
<h3>DownwardAPI</h3>
<pre data-id="downwardapi"><code data-trim data-noescape class="yaml" data-line-numbers="16-17|19-21|22-26">apiVersion: v1
kind: Pod
metadata:
  name: downwardapi-example
  labels:
    app: myapp
spec:
  containers:
  - name: nginx
    image: nginx
    volumeMounts:
    - name: downwardapi
      mountPath: /etc/podinfo
      readOnly: true
  volumes:
  - name: downwardapi
    downwardAPI:
      items:
      - path: &quot;metadata/labels&quot;
        fieldRef:
          fieldPath: metadata.labels
      - path: &quot;mem_limit&quot;
        resourceFieldRef:
          containerName: client-container
          resource: limits.memory
          divisor: 1Mi</code></pre>
</section>
<section >
<h3>Projected</h3>
<ul class="simple">
<li class="fragment"><p>ConfigMap</p></li>
<li class="fragment"><p>Secret</p></li>
<li class="fragment"><p>Downward API</p></li>
<li class="fragment"><p>ServiceAccountToken</p></li>
</ul>
</section>
<section >
<h3>Projected</h3>
<pre data-id="id79"><code data-trim data-noescape class="yaml" data-line-numbers="15-20">apiVersion: v1
kind: Pod
metadata:
  name: projected-example
spec:
  containers:
  - name: nginx
    image: nginx
    volumeMounts:
    - name: config
      mountPath: /etc/config
      readOnly: true
  volumes:
  - name: config
    projected:
      sources:
      - configMap:
          name: myconfigmap
      - secret:
          name: mysecret</code></pre>
</section>
<section >
<h3>Persistent Volumes</h3>
<a class="reference internal image-reference" href="_images/pv-l.svg"><img alt="_images/pv-l.svg" src="_images/pv-l.svg" width="500px" /></a>
</section>
<section >
<h3>Persistent Volumes</h3>
<pre data-id="id80"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|6-7|8|9-10|11|12|13-15|16-18">apiVersion: v1
kind: PersistentVolume
metadata:
  name: pv0003
spec:
  capacity:
    storage: 5Gi
  volumeMode: Filesystem
  accessModes:
    - ReadWriteOnce
  persistentVolumeReclaimPolicy: Recycle
  storageClassName: slow
  mountOptions:
    - hard
    - nfsvers=4.1
  nfs:
    path: /tmp
    server: 172.17.0.2</code></pre>
</section>
<section >
<h3>Persistent Volume Claim</h3>
<a class="reference internal image-reference" href="_images/pvc.svg"><img alt="_images/pvc.svg" src="_images/pvc.svg" width="500px" /></a>
</section>
<section >
<h3>Persistent Volume Claim</h3>
<pre data-id="id81"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|6-7|8|9-11|12|13-17">apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: myclaim
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem
  resources:
    requests:
      storage: 1Gi
  storageClassName: slow
  selector:
    matchLabels:
      release: &quot;stable&quot;
    matchExpressions:
      - {key: environment, operator: In, values: [dev]}</code></pre>
</section>
<section >
<h3>Persistent Volume Claim</h3>
<pre data-id="id82"><code data-trim data-noescape class="yaml" data-line-numbers="9-15">apiVersion: v1
kind: Pod
metadata:
  name: mypod
spec:
  containers:
    - name: myfrontend
      image: nginx
      volumeMounts:
      - mountPath: &quot;/var/www/html&quot;
        name: mypd
  volumes:
    - name: mypd
      persistentVolumeClaim:
        claimName: myclaim</code></pre>
</section>
<section >
<h3>Storage Classes</h3>
<a class="reference internal image-reference" href="_images/sc.svg"><img alt="_images/sc.svg" src="_images/sc.svg" width="500px" /></a>
</section>
<section >
<h3>Storage Classes</h3>
<pre data-id="id83"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|5-7|8|9|10-11|12">apiVersion: storage.k8s.io/v1
kind: StorageClass
metadata:
  name: standard
provisioner: kubernetes.io/aws-ebs
parameters:
  type: gp2
reclaimPolicy: Retain
allowVolumeExpansion: true
mountOptions:
  - debug
volumeBindingMode: Immediate</code></pre>
</section>
</section>
<section>
<section >
<h2>Access Control</h2>
<a class="reference internal image-reference" href="_images/acctl.svg"><img alt="_images/acctl.svg" src="_images/acctl.svg" width="200px" /></a>
</section>
<section >
<h3>Access Control</h3>
<a class="reference internal image-reference" href="_images/acctl-overview.svg"><img alt="_images/acctl-overview.svg" src="_images/acctl-overview.svg" width="700px" /></a>
</section>
<section >
<h3>Authentication</h3>
<p class="fragment"><img alt="" src="_images/user.svg" /></p>
<p class="fragment"><img alt="" src="_images/sa.svg" /></p>
</section>
<section >
<h3>Authentication strategies</h3>
<ul>
<li class="fragment"><p>X509 Client Certs</p>
<pre><code data-trim data-noescape class="bash">  openssl req -subj &quot;/CN=user/O=app1/O=app2&quot; -new -key key.pem
</code></pre>
</li>
<li class="fragment"><p>Bearer Token</p>
<pre><code data-trim data-noescape class="bash">  Authorization: Bearer $TOKEN
</code></pre>
</li>
<li class="fragment"><p>Authentication proxy</p>
<pre><code data-trim data-noescape class="bash">  X-Remote-User: user
  X-Remote-Group: app1
</code></pre>
</li>
</ul>
</section>
<section >
<h3>Authentication OIDC</h3>
<a class="reference internal image-reference" href="_images/oidc-example.svg"><img alt="_images/oidc-example.svg" src="_images/oidc-example.svg" width="700px" /></a>
</section>
<section >
<h3>Authentication resources</h3>
</section>
<section >
<h3>ServiceAccount</h3>
<pre data-id="serviceaccount"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|4-5|6|7-8|9-10">apiVersion: v1
kind: ServiceAccount
metadata:
  name: default
  namespace: default
automountServiceAccountToken: false
imagePullSecrets:
- name: myregistrykey
secrets:
- default-token-r4vrb</code></pre>
</section>
<section >
<h3>TokenRequest</h3>
<pre data-id="tokenrequest"><code data-trim data-noescape class="yaml" data-line-numbers="1|2-3|5-6|7-10|12-13">$ k create token default -o yaml
apiVersion: authentication.k8s.io/v1
kind: TokenRequest
metadata:
  name: default
  namespace: default
spec:
  audiences:
  - https://kubernetes.default.svc.cluster.local
  expirationSeconds: 3600
status:
  expirationTimestamp: &quot;&quot;
  token: eyJhbGciOiJSUzI1NiIsImtpZC...</code></pre>
</section>
<section >
<h3>TokenReview</h3>
<pre data-id="tokenreview"><code data-trim data-noescape class="bash" data-line-numbers="1-6|7-12|13|14-15|16|17-23">k create -o yaml -f - &lt;&lt; EOF
kind: TokenReview
apiVersion: authentication.k8s.io/v1
spec:
  token: eyJhbGc...
EOF
apiVersion: authentication.k8s.io/v1
kind: TokenReview
metadata:
  creationTimestamp: null
spec:
  token: eyJhbGc...
status:
  audiences:
  - https://kubernetes.default.svc.cluster.local
  authenticated: true
  user:
    groups:
    - system:serviceaccounts
    - system:serviceaccounts:default
    - system:authenticated
    uid: 54228ff0-d504-4416-a870-e3de7d53dc7c
    username: system:serviceaccount:default:default</code></pre>
</section>
<section >
<h3>CertificateSigningRequest</h3>
<pre data-id="certificatesigningrequest"><code data-trim data-noescape class="bash" data-line-numbers="1-5|7|8|9|10-11|13|14|16|17-24">cat &lt;&lt;EOF | kubectl apply -f -
apiVersion: certificates.k8s.io/v1
kind: CertificateSigningRequest
metadata:
  name: myuser
spec:
  request: LS0t...
  signerName: kubernetes.io/kube-apiserver-client
  expirationSeconds: 86400  # one day
  usages:
  - client auth
EOF
k certificate approve myuser
k get csr myuser -o jsonpath='{.status}' | jq
{
  &quot;certificate&quot;: &quot;LS0tL...&quot;,
  &quot;conditions&quot;: [
    {
      &quot;lastTransitionTime&quot;: &quot;&quot;,
      &quot;lastUpdateTime&quot;: &quot;&quot;,
      &quot;message&quot;: &quot;This CSR was approved by kubectl certificate approve.&quot;,
      &quot;reason&quot;: &quot;KubectlApprove&quot;,
      &quot;status&quot;: &quot;True&quot;,
      &quot;type&quot;: &quot;Approved&quot;</code></pre>
</section>
<section >
<h3>Authorization</h3>
<ul class="simple">
<li class="fragment"><p>Node</p></li>
<li class="fragment"><p>ABAC</p></li>
<li class="fragment"><p>RBAC</p></li>
<li class="fragment"><p>Webhook</p></li>
</ul>
</section>
<section >
<h3>RBAC Authorization</h3>
<ul class="simple">
<li class="fragment"><p>Role</p></li>
<li class="fragment"><p>RoleBinding</p></li>
<li class="fragment"><p>ClusterRole</p></li>
<li class="fragment"><p>ClusterRoleBinding</p></li>
</ul>
</section>
<section >
<h3>Authorization resources</h3>
</section>
<section >
<h3>Role</h3>
<pre data-id="role"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|4-5|6-9">apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  namespace: default
  name: pod-reader
rules:
- apiGroups: [&quot;&quot;] # &quot;&quot; indicates the core API group
  resources: [&quot;pods&quot;]
  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]</code></pre>
</section>
<section >
<h3>ClusterRole</h3>
<pre data-id="clusterrole"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|4-5|6-9">apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  # &quot;namespace&quot; omitted since ClusterRoles are not namespaced
  name: secret-reader
rules:
- apiGroups: [&quot;&quot;]
  resources: [&quot;secrets&quot;]
  verbs: [&quot;get&quot;, &quot;watch&quot;, &quot;list&quot;]</code></pre>
</section>
<section >
<h3>RoleBinding</h3>
<pre data-id="rolebinding"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|4-5|6-10|11-15|20-22|24-26|27-30">apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-pods
  namespace: default
subjects:
# You can specify more than one &quot;subject&quot;
- kind: User
  name: jane # &quot;name&quot; is case sensitive
  apiGroup: rbac.authorization.k8s.io
roleRef:
  # &quot;roleRef&quot; specifies the binding to a Role / ClusterRole
  kind: Role #this must be Role or ClusterRole
  name: pod-reader # name of the Role or ClusterRole
  apiGroup: rbac.authorization.k8s.io
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: read-secrets
  # This only grants permissions within the &quot;development&quot; namespace.
  namespace: development
subjects:
- kind: User
  name: dave # Name is case sensitive
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: secret-reader
  apiGroup: rbac.authorization.k8s.io</code></pre>
</section>
<section >
<h3>ClusterRoleBinding</h3>
<pre data-id="clusterrolebinding"><code data-trim data-noescape class="yaml" data-line-numbers="1-3|4-5|6-9|10-13">apiVersion: rbac.authorization.k8s.io/v1
# allows anyone in the &quot;manager&quot; group to read secrets in any namespace.
kind: ClusterRoleBinding
metadata:
  name: read-secrets-global
subjects:
- kind: Group
  name: manager # Name is case sensitive
  apiGroup: rbac.authorization.k8s.io
roleRef:
  kind: ClusterRole
  name: secret-reader
  apiGroup: rbac.authorization.k8s.io</code></pre>
</section>
<section >
<h3>SubjectAccessReview</h3>
<ul class="simple">
<li class="fragment"><p>SubjectAccessReview</p></li>
<li class="fragment"><p>LocalSubjectAccessReview</p></li>
<li class="fragment"><p>SelfSubjectAccessReview</p></li>
</ul>
</section>
<section >
<h3>SubjectAccessReview</h3>
<pre data-id="id85"><code data-trim data-noescape class="bash" data-line-numbers="1|3-4|6-10|11-12|13|15-17">k create -f - -o jsonpath='{.status}' &lt;&lt;EOF | jq
---
apiVersion: authorization.k8s.io/v1
kind: SubjectAccessReview
spec:
  resourceAttributes:
    namespace: default
    verb: get
    resource: pods
    version: v1
  groups:
    - system:masters
  user: kubernetes-admin
EOF
{
  &quot;allowed&quot;: true
}</code></pre>
</section>
<section >
<h3>SelfSubjectAccessReview</h3>
<pre data-id="selfsubjectaccessreview"><code data-trim data-noescape class="console" data-line-numbers="1-2">$ k auth can-i get pods
yes</code></pre>
</section>
<section >
<h3>SelfSubjectRulesReview</h3>
<pre data-id="selfsubjectrulesreview"><code data-trim data-noescape class="bash" data-line-numbers="1|2-3|4-5|7-19">k create -f - -o jsonpath='{.status.resourceRules}'&lt;&lt;EOF| jq
kind: SelfSubjectRulesReview
apiVersion: authorization.k8s.io/v1
spec:
  namespace: default
EOF
[
  {
    &quot;apiGroups&quot;: [
      &quot;*&quot;
    ],
    &quot;resources&quot;: [
      &quot;*&quot;
    ],
    &quot;verbs&quot;: [
      &quot;*&quot;
    ]
  },
...</code></pre>
</section>
<section >
<h3>SelfSubjectRulesReview</h3>
<pre data-id="id86"><code data-trim data-noescape class="console" data-line-numbers="1|2-17">$ k auth can-i --list
Resources  Non-Resource URLs   Resource Names   Verbs
*.*        []                  []               [*]
           [*]                 []               [*]
           [/api/*]            []               [get]
           [/api]              []               [get]
           [/apis/*]           []               [get]
           [/apis]             []               [get]
           [/healthz]          []               [get]
           [/healthz]          []               [get]
           [/livez]            []               [get]
           [/livez]            []               [get]
           [/openapi/*]        []               [get]
           [/openapi]          []               [get]
           [/readyz]           []               [get]
           [/readyz]           []               [get]
...</code></pre>
</section>
<section >
<h3>Admission Control</h3>
<a class="reference internal image-reference" href="_images/adm-ctl.png"><img alt="_images/adm-ctl.png" src="_images/adm-ctl.png" style="width: 700px;" /></a>
</section>
<section >
<h3>LimitRange</h3>
<pre data-id="limitrange"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|5-6|7-8|9-10|11-12|13-14|15">apiVersion: v1
kind: LimitRange
metadata:
  name: cpu-resource-constraint
spec:
  limits:
  - default: # this section defines default limits
      cpu: 500m
    defaultRequest: # this section defines default requests
      cpu: 500m
    max: # max and min define the limit range
      cpu: &quot;1&quot;
    min:
      cpu: 100m
    type: Container</code></pre>
</section>
<section >
<h3>ResourceQuota</h3>
<pre data-id="resourcequota"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|6-15|16-26">apiVersion: v1
kind: ResourceQuota
metadata:
  name: compute-resources
spec:
  hard:
    requests.cpu: &quot;1&quot;
    requests.memory: 1Gi
    limits.cpu: &quot;2&quot;
    limits.memory: 2Gi
    configmaps: &quot;10&quot;
    persistentvolumeclaims: &quot;4&quot;
    pods: &quot;4&quot;
    secrets: &quot;10&quot;
    services: &quot;10&quot;
status:
  used:
    configmaps: &quot;1&quot;
    limits.cpu: &quot;0&quot;
    limits.memory: &quot;0&quot;
    persistentvolumeclaims: &quot;1&quot;
    pods: &quot;1&quot;
    requests.cpu: &quot;0&quot;
    requests.memory: &quot;0&quot;
    secrets: &quot;1&quot;
    services: &quot;1&quot;</code></pre>
</section>
<section >
<h3>Pod Security Standards</h3>
<ul class="simple">
<li class="fragment"><p>Privileged</p></li>
<li class="fragment"><p>Baseline</p></li>
<li class="fragment"><p>Restricted</p></li>
</ul>
</section>
<section >
<h3>Pod Security Admission</h3>
<ul class="simple">
<li class="fragment"><p>enforce</p></li>
<li class="fragment"><p>audit</p></li>
<li class="fragment"><p>warn</p></li>
</ul>
<pre data-id="pod-security-admission"><code data-trim data-noescape class="yaml">apiVersion: v1
kind: Namespace
metadata:
  name: my-restricted-namespace
  labels:
    pod-security.kubernetes.io/enforce: restricted
    pod-security.kubernetes.io/enforce-version: latest
    pod-security.kubernetes.io/warn: restricted
    pod-security.kubernetes.io/warn-version: latest</code></pre>
</section>
<section >
<h3>Admission Webhooks</h3>
<ul class="simple">
<li class="fragment"><p>ValidatingWebhookConfiguration</p></li>
<li class="fragment"><p>MutatingWebhookConfiguration</p></li>
</ul>
</section>
<section >
<h3>Admission Webhooks</h3>
<pre data-id="id87"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|5|6|7-12|13-17|18-21">apiVersion: admissionregistration.k8s.io/v1
kind: ValidatingWebhookConfiguration
metadata:
  name: &quot;pod-policy.example.com&quot;
webhooks:
- name: &quot;pod-policy.example.com&quot;
  rules:
  - apiGroups:   [&quot;&quot;]
    apiVersions: [&quot;v1&quot;]
    operations:  [&quot;CREATE&quot;]
    resources:   [&quot;pods&quot;]
    scope:       &quot;Namespaced&quot;
  clientConfig:
    service:
      namespace: &quot;example-namespace&quot;
      name: &quot;example-service&quot;
    caBundle: &lt;CA_BUNDLE&gt;
  admissionReviewVersions: [&quot;v1&quot;]
  failurePolicy: Fail
  sideEffects: None
  timeoutSeconds: 5</code></pre>
</section>
</section>
<section>
<section >
<h2>kustomize/helm</h2>
<a class="reference internal image-reference" href="_images/kustomize.svg"><img alt="_images/kustomize.svg" src="_images/kustomize.svg" width="200px" /></a>
<a class="reference internal image-reference" href="_images/helm.svg"><img alt="_images/helm.svg" src="_images/helm.svg" width="200px" /></a>
</section>
<section >
<h3>Deploy</h3>
<p>YAML Files:</p>
<ul class="simple">
<li class="fragment"><p>Deployment</p></li>
<li class="fragment"><p>Service</p></li>
<li class="fragment"><p>Ingress</p></li>
<li class="fragment"><p>ConfigMap</p></li>
<li class="fragment"><p>Secret</p></li>
</ul>
</section>
<section >
<h3>Deploy</h3>
<pre data-id="id88"><code data-trim data-noescape class="console" data-line-numbers="1-4|5-8">deploy/
├── deployment.yaml
├── ingress.yaml
└── service.yaml
$ kubectl apply -f deploy
deployment.apps/app created
ingress.networking.k8s.io/app created
service/app created</code></pre>
</section>
<section >
<h3>Kustomize</h3>
<pre data-id="kustomize"><code data-trim data-noescape class="yaml" data-line-numbers="1|2-5|6|7|8-9"># kustomization.yaml
resources:
- deployment.yaml
- service.yaml
- ingress.yaml
namePrefix: dev-
namespace: development
commonLabels:
  environment: development</code></pre>
</section>
<section >
<h3>Kustomize</h3>
<pre data-id="id89"><code data-trim data-noescape class="console">$ kustomize build
$ kubectl kustomize
$ kubectl apply -k</code></pre>
</section>
<section >
<h3>Kustomize</h3>
<pre data-id="id90"><code data-trim data-noescape class="console" data-line-numbers="1-5|6-9">deploy/
├── deployment.yaml
├── ingress.yaml
├── kustomization.yaml
└── service.yaml
$ kubectl apply -k deploy
service/dev-app created
deployment.apps/dev-app created
ingress.networking.k8s.io/dev-app created</code></pre>
</section>
<section >
<h3>Environment</h3>
<ul class="simple">
<li class="fragment"><p>Dev</p></li>
<li class="fragment"><p>Test(ift/lt)</p></li>
<li class="fragment"><p>Stage</p></li>
<li class="fragment"><p>Prod</p></li>
</ul>
</section>
<section >
<h3>Kustomize Overlays</h3>
<pre data-id="kustomize-overlays"><code data-trim data-noescape class="console" data-line-numbers="2-6|7-8|9-10|11-12">deploy/
├── base
│   ├── deployment.yaml
│   ├── ingress.yaml
│   ├── kustomization.yaml
│   └── service.yaml
├── dev
│   └── kustomization.yaml
├── prod
│   └── kustomization.yaml
└── stage
    └── kustomization.yaml</code></pre>
</section>
<section >
<h3>Kustomize Overlays</h3>
<pre data-id="id92"><code data-trim data-noescape class="yaml" data-line-numbers="1-7|8-14"># deploy/dev/kustomization.yaml
resources:
- ../base
namePrefix: dev-
namespace: development
commonLabels:
  environment: development
# deploy/prod/kustomization.yaml
resources:
- ../base
namePrefix: prod-
namespace: production
commonLabels:
  environment: production</code></pre>
</section>
<section >
<h3>Kustomize Overlays</h3>
<pre data-id="id93"><code data-trim data-noescape class="console" data-line-numbers="1-4|5-8">$ kubectl apply -k deploy/dev
service/dev-app created
deployment.apps/dev-app created
ingress.networking.k8s.io/dev-app created
$ kubectl apply -k deploy/prod
service/prod-app created
deployment.apps/prod-app created
ingress.networking.k8s.io/prod-app created</code></pre>
</section>
<section >
<h3>Kustomize built-ins</h3>
<ul class="simple">
<li class="fragment"><p>Transformers</p></li>
<li class="fragment"><p>Generators</p></li>
</ul>
</section>
<section >
<h3>Kustomize Transformers</h3>
<ul class="simple">
<li class="fragment"><p>namePrefix</p></li>
<li class="fragment"><p>nameSuffix</p></li>
<li class="fragment"><p>commonAnnotations</p></li>
<li class="fragment"><p>images</p></li>
<li class="fragment"><p>commonLabels</p></li>
<li class="fragment"><p>namespace</p></li>
<li class="fragment"><p>replicas</p></li>
<li class="fragment"><p>patches</p></li>
</ul>
</section>
<section >
<h3>Kustomize Generators</h3>
<ul class="simple">
<li class="fragment"><p>configMapGenerator</p></li>
<li class="fragment"><p>secretGenerator</p></li>
<li class="fragment"><p>helmCharts</p></li>
</ul>
</section>
<section >
<h3>Helm</h3>
<ul class="simple">
<li class="fragment"><p>Chart</p></li>
<li class="fragment"><p>Release</p></li>
<li class="fragment"><p>Repository</p></li>
</ul>
</section>
<section >
<h3>Helm Chart</h3>
<pre data-id="helm-chart"><code data-trim data-noescape class="console" data-line-numbers="1-2|4-17|5|6|7-16|10-14|8|9|15-16|17">$ helm create chart
Creating chart
$ tree chart/
chart/
├── Chart.yaml
├── charts
├── templates
│   ├── NOTES.txt
│   ├── _helpers.tpl
│   ├── deployment.yaml
│   ├── hpa.yaml
│   ├── ingress.yaml
│   ├── service.yaml
│   ├── serviceaccount.yaml
│   └── tests
│       └── test-connection.yaml
└── values.yaml</code></pre>
</section>
<section >
<h3>Helm Chart</h3>
<pre data-id="id94"><code data-trim data-noescape class="yaml" data-line-numbers="1|2|3|4|5|6|7|8"># chart/Chart.yaml
apiVersion: v2
name: chart
description: A Helm chart for Kubernetes
type: application
version: 0.1.0
appVersion: &quot;1.16.0&quot;
dependencies: []</code></pre>
</section>
<section >
<h3>Helm Templates</h3>
<pre data-id="helm-templates"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|3-6|8-13|15">apiVersion: v1
kind: Service
metadata:
  name: {{ include &quot;chart.fullname&quot; . }}
  labels:
    {{- include &quot;chart.labels&quot; . | nindent 4 }}
spec:
  type: {{ .Values.service.type }}
  ports:
    - port: {{ .Values.service.port }}
      targetPort: http
      protocol: TCP
      name: http
  selector:
    {{- include &quot;chart.selectorLabels&quot; . | nindent 4 }}</code></pre>
</section>
<section >
<h3>Helm Templates</h3>
<pre data-id="id95"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|4|5-17|7|8-10|11-13|14-17">apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Release.Name }}-configmap
data:
  myvalue: &quot;Hello World&quot;
  drink: {{ .Values.favorite.drink | default &quot;tea&quot; | quote }}
  {{ if eq .Values.favorite.drink &quot;coffee&quot; }}
  mug: &quot;true&quot;
  {{ end }}
  {{- with .Values.favorite }}
  food: {{ .food | upper | quote }}
  {{- end }}
  toppings: |-
  {{- range .Values.pizzaToppings }}
  - {{ . | title | quote }}
  {{- end }}</code></pre>
</section>
<section >
<h3>Helm Template Objects</h3>
<ul class="simple">
<li class="fragment"><p>Release</p></li>
<li class="fragment"><p>Values</p></li>
<li class="fragment"><p>Chart</p></li>
<li class="fragment"><p>Files</p></li>
<li class="fragment"><p>Capabilities</p></li>
<li class="fragment"><p>Template</p></li>
</ul>
</section>
<section >
<h3>Helm Template Functions</h3>
<ul class="simple">
<li class="fragment"><p>Logic and Flow Control</p></li>
<li class="fragment"><p>String</p></li>
<li class="fragment"><p>Regular Expressions</p></li>
<li class="fragment"><p>Encoding</p></li>
<li class="fragment"><p>Math</p></li>
<li class="fragment"><p>Cryptographic and Security</p></li>
</ul>
<p class="fragment">and many others(github.com/Masterminds/sprig)</p>
</section>
<section >
<h3>Helm Repo</h3>
<pre data-id="helm-repo"><code data-trim data-noescape class="console" data-line-numbers="1-5|6-7|8-10|11-14|15-19|20-24">$ helm search hub wordpress
URL                                                 CHART VERSION APP VERSION DESCRIPTION
https://hub.helm.sh/charts/bitnami/wordpress        7.6.7         5.2.4       Web publishing platform...
https://hub.helm.sh/charts/presslabs/wordpress-...  v0.6.3        v0.6.3      Presslabs WordPress
https://hub.helm.sh/charts/presslabs/wordpress-...  v0.7.1        v0.7.1      A Helm chart for deploy...
$ helm repo add brigade https://brigadecore.github.io/charts
&quot;brigade&quot; has been added to your repositories
$ helm repo list
NAME            URL
brigade         https://brigadecore.github.io/charts
$ helm repo update
Hang tight while we grab the latest from your chart repositories...
...Successfully got an update from the &quot;opensearch&quot; chart repository
Update Complete. ⎈Happy Helming!⎈
$ helm search repo brigade
NAME                          CHART VERSION APP VERSION DESCRIPTION
brigade/brigade               1.3.2         v1.2.1      Brigade provides event-driven scripting of...
brigade/brigade-github-app    0.4.1         v0.2.1      The Brigade GitHub App, an advanced gateway...
brigade/brigade-github-oauth  0.2.0         v0.20.0     The legacy OAuth GitHub Gateway for Brigade
$ helm show all brigade/brigade
# chart
# values
# crds
# readme</code></pre>
</section>
<section >
<h3>Helm Release</h3>
<pre data-id="helm-release"><code data-trim data-noescape class="console" data-line-numbers="1-9|10-12|13-17|18-27|28-31|32-33|34-38|39-40">$ helm install grafana/grafana --generate-name \
  -f values.yaml --set key=value
NAME: grafana-1684182240
LAST DEPLOYED: Mon May 15 23:24:01 2023
NAMESPACE: default
STATUS: deployed
REVISION: 1
NOTES:
...
$ helm list
NAME               NAMESPACE REVISION UPDATED             STATUS   CHART          APP VERSION
grafana-1684182240 default   1        2023-05-15 23:24:01 deployed grafana-6.56.4 9.5.2
$ helm get all grafana-1684182240
# hooks
# manifest
# notes
# values
$ helm upgrade grafana-1684182240 grafana/grafana \
  --set key=value2
Release &quot;grafana-1684182240&quot; has been upgraded. Happy Helming!
NAME: grafana-1684182240
LAST DEPLOYED: Mon May 15 23:29:51 2023
NAMESPACE: default
STATUS: deployed
REVISION: 2
NOTES:
...
$ helm history grafana-1684182240
REVISION UPDATED                  STATUS     CHART          APP VERSION DESCRIPTION
1        Mon May 15 23:24:01 2023 superseded grafana-6.56.4 9.5.2       Install complete
2        Mon May 15 23:29:51 2023 deployed   grafana-6.56.4 9.5.2       Upgrade complete
$ helm rollback grafana-1684182240 1
Rollback was a success! Happy Helming!
$ helm history grafana-1684182240
REVISION UPDATED                  STATUS     CHART          APP VERSION DESCRIPTION
1        Mon May 15 23:24:01 2023 superseded grafana-6.56.4 9.5.2       Install complete
2        Mon May 15 23:29:51 2023 superseded grafana-6.56.4 9.5.2       Upgrade complete
3        Mon May 15 23:31:50 2023 deployed   grafana-6.56.4 9.5.2       Rollback to 1
$ helm uninstall grafana-1684182240
release &quot;grafana-1684182240&quot; uninstalled</code></pre>
</section>
</section>
<section>
<section >
<h2>Operators</h2>
<a class="reference internal image-reference" href="_images/operatorframework.svg"><img alt="_images/operatorframework.svg" src="_images/operatorframework.svg" width="200px" /></a>
</section>
<section >
<h3>Operator</h3>
<ul class="simple">
<li><p>Custom Resource</p></li>
<li><p>Control Loop</p></li>
</ul>
</section>
<section >
<h3>Operator</h3>
<p>Examples:</p>
<ul class="simple">
<li class="fragment"><p>Etcd Operator</p></li>
<li class="fragment"><p>Prometheus Operator</p></li>
<li class="fragment"><p>MySQL Operator</p></li>
</ul>
</section>
<section >
<h3>Custom Resources</h3>
<ul class="simple">
<li class="fragment"><p>API Aggregation</p></li>
<li class="fragment"><p>CRD</p></li>
</ul>
</section>
<section >
<h3>API Aggregation</h3>
<pre data-id="api-aggregation"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|4|6-7|8-9|10-12|13">apiVersion: apiregistration.k8s.io/v1
kind: APIService
metadata:
  name: &lt;name of the registration object&gt;
spec:
  group: &lt;API group name this extension apiserver hosts&gt;
  version: &lt;API version this extension apiserver hosts&gt;
  groupPriorityMinimum: &lt;priority this APIService for this group, see API documentation&gt;
  versionPriority: &lt;prioritizes ordering of this version within a group, see API documentation&gt;
  service:
    namespace: &lt;namespace of the extension apiserver service&gt;
    name: &lt;name of the extension apiserver service&gt;
  caBundle: &lt;pem encoded ca cert that signs the server cert used by the webhook&gt;</code></pre>
</section>
<section >
<h3>API Aggregation</h3>
<a class="reference internal image-reference" href="_images/api-aggregation.svg"><img alt="_images/api-aggregation.svg" src="_images/api-aggregation.svg" width="800px" /></a>
</section>
<section >
<h3>CRD</h3>
<pre data-id="crd"><code data-trim data-noescape class="yaml" data-line-numbers="1-2|4-5|7-8|9-10|11-20|12-13|14-15|16-17|18-20|23-40|23-27|28-40">apiVersion: apiextensions.k8s.io/v1
kind: CustomResourceDefinition
metadata:
  # name must match the spec fields below, and be in the form: &lt;plural&gt;.&lt;group&gt;
  name: crontabs.stable.example.com
spec:
  # group name to use for REST API: /apis/&lt;group&gt;/&lt;version&gt;
  group: stable.example.com
  # either Namespaced or Cluster
  scope: Namespaced
  names:
    # plural name to be used in the URL: /apis/&lt;group&gt;/&lt;version&gt;/&lt;plural&gt;
    plural: crontabs
    # singular name to be used as an alias on the CLI and for display
    singular: crontab
    # kind is normally the CamelCased singular type. Your resource manifests use this.
    kind: CronTab
    # shortNames allow shorter string to match your resource on the CLI
    shortNames:
    - ct
  # list of versions supported by this CustomResourceDefinition
  versions:
    - name: v1
      # Each version can be enabled/disabled by Served flag.
      served: true
      # One and only one version must be marked as the storage version.
      storage: true
      schema:
        openAPIV3Schema:
          type: object
          properties:
            spec:
              type: object
              properties:
                cronSpec:
                  type: string
                image:
                  type: string
                replicas:
                  type: integer</code></pre>
</section>
<section >
<h3>Operator Pattern</h3>
<a class="reference internal image-reference" href="_images/operator_pattern.png"><img alt="_images/operator_pattern.png" src="_images/operator_pattern.png" style="width: 1000px;" /></a>
</section>
<section >
<h3>Operator Components</h3>
<a class="reference internal image-reference" href="_images/operator_components.png"><img alt="_images/operator_components.png" src="_images/operator_components.png" style="width: 1000px;" /></a>
</section>
<section >
<h3>Kubernetes Clients</h3>
<p>Officially-supported</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>C</p></td>
<td><p>Go</p></td>
<td><p>CSharp</p></td>
</tr>
<tr class="row-odd"><td><p>Haskell</p></td>
<td><p>Java</p></td>
<td><p>JavaScript</p></td>
</tr>
<tr class="row-even"><td><p>Perl</p></td>
<td><p>Python</p></td>
<td><p>Ruby</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</section>
<section >
<h3>Kubernetes Clients</h3>
<p>Community-maintained</p>
<table class="docutils align-default">
<thead>
<tr class="row-odd"><th class="head"><p></p></th>
<th class="head"><p></p></th>
<th class="head"><p></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Clojure</p></td>
<td><p>Elixir</p></td>
<td><p>Lisp</p></td>
</tr>
<tr class="row-odd"><td><p>Node.js</p></td>
<td><p>PHP</p></td>
<td><p>Rust</p></td>
</tr>
<tr class="row-even"><td><p>Scala</p></td>
<td><p>Swift</p></td>
<td><p>DotNet</p></td>
</tr>
<tr class="row-odd"><td><p></p></td>
<td><p></p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
</section>
<section >
<h3>Operator Frameworks</h3>
<ul class="simple">
<li><p>KUDO (Kubernetes Universal Declarative Operator)</p></li>
<li><p>Metacontroller (along with WebHooks that you implement yourself)</p></li>
<li><p>Shell-operator</p></li>
</ul>
</section>
<section >
<h3>Operator Frameworks</h3>
<ul class="simple">
<li><p>Java Operator SDK</p></li>
<li><p>Kopf (Kubernetes Operator Pythonic Framework)</p></li>
<li><p>KubeOps (.NET operator SDK)</p></li>
</ul>
</section>
<section >
<h3>Operator Frameworks</h3>
<ul class="simple">
<li><p>kubebuilder</p></li>
<li><p>Operator Framework</p></li>
</ul>
</section>
<section >
<h3>Operator Framework</h3>
<ul class="simple">
<li class="fragment"><p>BUILD: operator-sdk</p></li>
<li class="fragment"><p>MANAGE: olm</p></li>
<li class="fragment"><p>DISCOVER: operatorhub.io</p></li>
</ul>
</section>
<section >
<h3>Operator SDK</h3>
<ul class="simple">
<li class="fragment"><p>GO</p></li>
<li class="fragment"><p>Ansible</p></li>
<li class="fragment"><p>Helm</p></li>
</ul>
</section>
<section >
<h3>Operator SDK</h3>
<pre data-id="id101"><code data-trim data-noescape class="console" data-line-numbers="1-3|4-6|7-19">$ operator-sdk init \
  --domain example.com \
  --repo github.com/example/memcached-operator
$ operator-sdk create api \
  --group cache --version v1alpha1 \
  --kind Memcached --resource --controller
$ ls -1
Dockerfile
Makefile
PROJECT
README.md
api/
bin/
config/
controllers/
go.mod
go.sum
hack/
main.go</code></pre>
</section>
<section >
<h3>Operator SDK</h3>
<p><code class="docutils literal notranslate"><span class="pre">api/v1alpha1/memcached_types.go</span></code></p>
<pre data-id="id102"><code data-trim data-noescape class="go" data-line-numbers="1-2|3-4|5-9|11-13|15-17|20-21|22-29|31-33|36-44">// MemcachedSpec defines the desired state of Memcached
type MemcachedSpec struct {
	// INSERT ADDITIONAL SPEC FIELDS - desired state of cluster
	// Important: Run &quot;make&quot; to regenerate code after modifying this file
// The following markers will use OpenAPI v3 schema to validate the value
	// More info: https://book.kubebuilder.io/reference/markers/crd-validation.html
	// +kubebuilder:validation:Minimum=1
	// +kubebuilder:validation:Maximum=5
	// +kubebuilder:validation:ExclusiveMaximum=false

	// Size defines the number of Memcached instances
	// +operator-sdk:csv:customresourcedefinitions:type=spec
	Size int32 `json:&quot;size,omitempty&quot;`

	// Port defines the port that will be used to init the container with the image
	// +operator-sdk:csv:customresourcedefinitions:type=spec
	ContainerPort int32 `json:&quot;containerPort,omitempty&quot;`
}

// MemcachedStatus defines the observed state of Memcached
type MemcachedStatus struct {
	// Represents the observations of a Memcached's current state.
	// Memcached.status.conditions.type are: &quot;Available&quot;, &quot;Progressing&quot;, and &quot;Degraded&quot;
	// Memcached.status.conditions.status are one of True, False, Unknown.
	// Memcached.status.conditions.reason the value should be a CamelCase string and producers of specific
	// condition types may define expected values and meanings for this field, and whether the values
	// are considered a guaranteed API.
	// Memcached.status.conditions.Message is a human readable message indicating details about the transition.
	// For further information see: https://github.com/kubernetes/community/blob/master/contributors/devel/sig-architecture/api-conventions.md#typical-status-properties

	// Conditions store the status conditions of the Memcached instances
	// +operator-sdk:csv:customresourcedefinitions:type=status
	Conditions []metav1.Condition `json:&quot;conditions,omitempty&quot; patchStrategy:&quot;merge&quot; patchMergeKey:&quot;type&quot; protobuf:&quot;bytes,1,rep,name=conditions&quot;`
}

// Memcached is the Schema for the memcacheds API
//+kubebuilder:subresource:status
type Memcached struct {
	metav1.TypeMeta   `json:&quot;,inline&quot;`
	metav1.ObjectMeta `json:&quot;metadata,omitempty&quot;`

	Spec   MemcachedSpec   `json:&quot;spec,omitempty&quot;`
	Status MemcachedStatus `json:&quot;status,omitempty&quot;`
}</code></pre>
</section>
<section >
<h3>Operator SDK</h3>
<pre data-id="id103"><code data-trim data-noescape class="console" data-line-numbers="1-2|3-4">$ make generate
# api/v1alpha1/zz_generated.deepcopy.go
$ make manifests
# config/crd/bases/cache.example.com_memcacheds.yaml</code></pre>
</section>
<section >
<h3>Operator SDK</h3>
<p><code class="docutils literal notranslate"><span class="pre">controllers/memcached_controller.go</span></code></p>
<pre data-id="id104"><code data-trim data-noescape class="go" data-line-numbers="1-6|3|4|8-15">func (r *Reconciler) SetupWithManager(mgr ctrl.Manager) error {
	return ctrl.NewControllerManagedBy(mgr).
		For(&amp;cachev1alpha1.Memcached{}).
		Owns(&amp;appsv1.Deployment{}).
		Complete(r)
}

func (r *Reconciler) Reconcile(
  ctx context.Context, req ctrl.Request,
) (ctrl.Result, error) {
  // Lookup the Memcached instance for this reconcile request
  memcached := &amp;cachev1alpha1.Memcached{}
  err := r.Get(ctx, req.NamespacedName, memcached)
  ...
}</code></pre>
</section>
<section >
<h3>Operator SDK</h3>
<pre data-id="id105"><code data-trim data-noescape class="console">$ make manifests
$ IMG=example.com/memcached-operator:v0.0.1 make docker-build
$ IMG=example.com/memcached-operator:v0.0.1 make deploy</code></pre>
<style type="text/css">
    /* 1. Style header/footer <div> so they are positioned as desired. */
    #header-left {
        position: absolute;
        top: 0%;
        left: 0%;
    }
    #header-right {
        position: absolute;
        top: 0%;
        right: 0%;
    }
    #footer-left {
        position: absolute;
        bottom: 0%;
        left: 0%;
    }
</style>
<div id="hidden" style="display:none;">
    <div id="header">
        <div id="header-left"></div>
        <div id="header-right"></div>
        <div id="footer-left"></div>
    </div>
</div>
<script src="_static/jquery.js"></script>
<script type="text/javascript">
    var header = $('#header').html();
    if ( window.location.search.match( /print-pdf/gi ) ) {
        Reveal.addEventListener( 'ready', function( event ) {
            $('.slide-background').append(header);
        });
    }
    else {
        $('div.reveal').append(header);
   }
</script></section>
</section>

        </div>
    </div>
    
    <script src="_static/revealjs4/dist/reveal.js"></script>
    
    
      <script src="_static/revealjs4/plugin/highlight/highlight.js"></script>
      <script src="_static/revealjs4/plugin/mermaid/mermaid.js"></script>
      
    
    <script>
        var revealjsConfig = new Object();
        Object.assign(revealjsConfig, JSON.parse('null'));
        
        
        
          revealjsConfig.plugins = [
            RevealHighlight,mermaid,
          ];
        
        // More info https://github.com/hakimel/reveal.js#configuration
        Reveal.initialize(revealjsConfig);
    </script>

  </body>
</html>